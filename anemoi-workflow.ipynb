{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f2d5fa-e962-4bce-8ff3-c03ec072addc",
   "metadata": {},
   "source": [
    "# 1) Generate Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df1fda-715f-4e38-850e-4e54ed19dedc",
   "metadata": {},
   "source": [
    "## 1.1) Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90c1b9d-b2c7-4d96-b903-1e5eb6727532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco training.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1e4c3-ccd0-4c00-83c1-12b1d2661ba2",
   "metadata": {},
   "source": [
    "## 1.2) Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f194c6a-d0d5-46b0-a977-38a046c9f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco validation.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1c92a-8762-4dd4-a8a4-95d0e1733fb1",
   "metadata": {},
   "source": [
    "## 1.3) Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715dd231-03cd-481d-950e-9a0ae224b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco testing.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f4a5f-bfe5-444c-8192-24dff163d48d",
   "metadata": {},
   "source": [
    "# 2) Generate and Modify Config Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69f2e1-ae5b-43ec-aac8-52bf948b8c91",
   "metadata": {},
   "source": [
    "## 2.1) Generate Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01ad47-a98e-4428-b12f-d5b3a84f9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-02 17:52:09 INFO Generating configs, please wait.\n"
     ]
    }
   ],
   "source": [
    "!anemoi-training config generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80579896-e0ae-4f19-bc57-60f8982ad949",
   "metadata": {},
   "source": [
    "The config files generated have many settings that need to be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6455de1-b5e3-420d-aa3e-58eaa497776a",
   "metadata": {},
   "source": [
    "## 2.2) Define batch sizes and configure datasets\n",
    "\n",
    "Batch sizes must be defined for each dataset. The default *dataloader* file *dataloader/native_grid.yaml* has pre-defined batch sizes, however these can be overriden in *config.yaml*.\n",
    "- **dataloader.batch_size.training**: training dataset batch size\n",
    "- **dataloader.batch_size.validation**: validation dataset batch size\n",
    "- **dataloader.batch_size.test**: testing dataset batch size\n",
    "\n",
    "For each dataset, the dataset path and start and end dates need to be specified.\n",
    "- **dataloader.training.dataset**: full path to the training dataset\n",
    "- **dataloader.training.start**: start date for training dataset (YYYY-MM-DD)\n",
    "- **dataloader.training.end**: end date for training dataset (YYYY-MM-DD)\n",
    "- **dataloader.validation.dataset**: full path to the validation dataset\n",
    "- **dataloader.validation.start**: start date for validation dataset (YYYY-MM-DD)\n",
    "- **dataloader.validation.end**: end date for validation dataset (YYYY-MM-DD)\n",
    "- **dataloader.test.dataset**: full path to the test dataset\n",
    "- **dataloader.test.start**: start date for test dataset (YYYY-MM-DD)\n",
    "- **dataloader.test.end**: end date for test dataset (YYYY-MM-DD)\n",
    "\n",
    "Example implementation in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1d45ee-0e0f-401a-8ecc-5e91cdb662e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (4061005375.py, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstart: 1994-01-01T00\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "dataloader:\n",
    "  batch_size:\n",
    "    training: 2\n",
    "    validation: 2\n",
    "    test: 2\n",
    "  training:\n",
    "    dataset: ${hardware.paths.data}/training.zarr\n",
    "    start: 1994-01-01\n",
    "    end: 1994-01-31\n",
    "  validation:\n",
    "    dataset: ${hardware.paths.data}/validation.zarr\n",
    "    start: 1994-02-01\n",
    "    end: 1994-02-28\n",
    "  test:\n",
    "    dataset: ${hardware.paths.data}/testing.zarr\n",
    "    start: 1994-03-01\n",
    "    end: 1994-03-31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a49d4d-20c0-4380-bccf-d22263497f56",
   "metadata": {},
   "source": [
    "## 2.3) Configure GPUs and Paths\n",
    "\n",
    "One of the most important steps for running the Anemoi framework is configuring paths. At the top of *config.yaml*, the 'hardware' parameter should be set to 'example'. This calls the default settings in *hardware/example.yaml*, however the **data** path is not specified in the *example* yaml. In addition, you may want to specify different directories for storing outputs and model graphs.\n",
    "\n",
    "- **hardware.paths.output**: directory for the outputs (checkpoints, plots, etc.). Directory structure will be created if it does not already exist.\n",
    "- **hardware.paths.data**: directory for the datasets generated with ufs2arco.\n",
    "- **hardware.paths.graph**: directory for the model graph.\n",
    "\n",
    "The name of the zarr file containing the training dataset must also be specified.\n",
    "- **hardware.files.dataset**: name of the training dataset zarr file (do not include absolute path with directory structure)\n",
    "\n",
    "You can also specify the number of GPUs to use for each model with the **hardware.num_gpus_per_model** parameter.\n",
    "\n",
    "An example implementation in *config.yaml* is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e2885-3cb3-4f68-bf83-4bd7ff5d65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardware:\n",
    "\n",
    "  num_gpus_per_model: 1\n",
    "\n",
    "  paths:\n",
    "    output: p1/training-output/\n",
    "    data: p1/dataset\n",
    "    graph: p1/graph\n",
    "\n",
    "  files:\n",
    "    dataset: training.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ed49c-d159-4b4b-8751-19d78432b833",
   "metadata": {},
   "source": [
    "## 2.4) Configure Model Training\n",
    "\n",
    "There are a few parameters that should be specified in the main *config.yaml* file so model training configurations can be easily modified.\n",
    "\n",
    "At the top of *config.yaml*, you will probably see a 'training' parameter that is set to 'default'. This calls training configuration settings in the *training/default.yaml* file. All of these settings can be overriden in *config.yaml*.\n",
    "\n",
    "Here are some useful training parameters to include in *config.yaml*:\n",
    "- **training.max_epochs**: specifies the maximum number of epochs for model training. Training will stop if this limit is reached.\n",
    "- **training.max_steps**: specifies the maximum number of total steps for model training (*not steps per epoch*). Training will stop if this limit is reached.\n",
    "- **training.lr.rate**: starting learning rate\n",
    "- **training.lr.min**: minimum learning rate\n",
    "\n",
    "An example implementation in *config.yaml* with the aforementioned parameters is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf1895f-b515-4751-820e-8700917cd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "training:\n",
    "  max_epochs: 500\n",
    "  max_steps: 10000\n",
    "  lr:\n",
    "    rate: 1e-4\n",
    "    min: 3e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8c525-c0f6-481c-b7cc-978cd37b2ace",
   "metadata": {},
   "source": [
    "## 2.5) Configure Diagnostics\n",
    "\n",
    "During training, it is useful to plot sample model predictions and log other information pertaining to the model output/performance in order to get a good idea if your model is 'working' as intended.\n",
    "\n",
    "In the *config.yaml* file, the default file for diagnostics is *diagnostics/evaluation.yaml*. There are a couple empty fields that we will need to define in the following steps.\n",
    "\n",
    "### 2.5.1) Performance Logging\n",
    "\n",
    "For now, we will disable Weights and Biases for performance logging (though you may want to configure a WandB workflow in the future). This can be done by setting the **diagnostics.log.wandb.entity** parameter to 'null'.\n",
    "\n",
    "We will also disable the MLflow tracking server by setting **diagnostics.log.mlflow.tracking_uri** to 'null'.\n",
    "\n",
    "An example implementation in *config.yaml* is shown below. Note that we will continue to modify **diagnostics** in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee8437-e6a7-43c7-bd06-98aaccd88d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6c6d9-5db9-4d0a-b35f-52e13402f25c",
   "metadata": {},
   "source": [
    "### 2.5.2) Plotting\n",
    "\n",
    "With the default settings in *diagnostics/evaluation.yaml*, the following plots will be produced at user-defined frequencies for specified variables:\n",
    "* Spatial plots of model predictions and errors\n",
    "* Histograms showing binned model predictions and errors for **every** variable in a single plot\n",
    "\n",
    "The frequency of plotting can be modified directly in *config.yaml* with the following parameters:\n",
    "* **diagnostics.plot.frequency.epoch**: plot frequency in epochs\n",
    "* **diagnostics.plot.frequency.batch**: plot frequency in batches\n",
    "\n",
    "Adding these to **diagnostics** in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14c0af-a659-4e3c-8470-496084e99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null\n",
    "  plot:\n",
    "    frequency:\n",
    "      epoch: 5\n",
    "      batch: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01aa95-30a3-499e-bd12-5c415a58311f",
   "metadata": {},
   "source": [
    "The next thing to do is define what variables we want to plot. \n",
    "\n",
    "First, let's modify a few lines in *diagnostics/evaluation.yaml*.\n",
    "- Under **callbacks**, assure that every instance of **parameters** (should be three instances in total) calls back to the user-specified variables in **diagnostics.plot.parameters** (see cell below). This will make sure that plots include every variable that you would like to monitor.\n",
    "- You can leave the instance of **parameters** near the top of the file unchanged as we will be overriding it in *config.yaml*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f432e44-07ff-40b2-9ce3-8c1488e812be",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters: ${diagnostics.plot.parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc78fb-ee49-4040-8589-e2eb7368a350",
   "metadata": {},
   "source": [
    "Now that the plotting file is configured, we can add define the variables we want to plot in *config.yaml*.\n",
    "* Note that precipitation and related moisture variables need to be defined in **diagnostics.plot.precip_and_related_fields** as well as **diagnostics.plot.parameters**.\n",
    "\n",
    "Adding our desired variables for plotting to **diagnostics.plot** in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45764717-ad87-4b42-a3fa-264034c368c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null\n",
    "  plot:\n",
    "    frequency:\n",
    "      epoch: 1\n",
    "      batch: 5\n",
    "    parameters:\n",
    "      - tmp_825  # 825 hPa temperature\n",
    "      - tmp2m  # 2-meter temperature\n",
    "    precip_and_related_fields: []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20167b36-f068-43ec-a1ae-4d76e44ddf43",
   "metadata": {},
   "source": [
    "After configuring the diagnostics, the *config.yaml* file can be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ad9da-5bd8-42d2-a931-9dce5ffd6f8c",
   "metadata": {},
   "source": [
    "# 3) Set Environment Variables\n",
    "\n",
    "Anemoi requires a \"base seed\" and a SLURM job ID.\n",
    "- The base seed is used to initialize model weights. Changing the seed will result in different initial model parameters.\n",
    "- The SLURM job ID is required, even if you are not on SLURM (just leave it as \"0\").\n",
    "\n",
    "*Hydra* can be configured to output more complete tracebacks for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce40c91-442d-4533-8199-8465cdf61b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### Required ###\n",
    "os.environ[\"ANEMOI_BASE_SEED\"] = \"42\"\n",
    "os.environ[\"SLURM_JOB_ID\"] = \"0\"\n",
    "\n",
    "### Optional ###\n",
    "os.environ['HYDRA_FULL_ERROR'] = \"1\"  # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cc428-3369-42e4-9fd6-8abc9b8116a3",
   "metadata": {},
   "source": [
    "## 4) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463104c-5f43-4b05-848d-5bcfa232d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "!anemoi-training train --config-name=config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17722f48-70fa-4c94-8bcd-88aa6847a41a",
   "metadata": {},
   "source": [
    "## 5) Model Inference\n",
    "\n",
    "Model inference with Anemoi is performed with the *anemoi-inference* module: https://anemoi.readthedocs.io/projects/inference/en/latest/index.html#index-page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc7ed4-63df-448c-996a-a6401024ce52",
   "metadata": {},
   "source": [
    "### 5.1) Retrieve Model Runs and Load Checkpoint\n",
    "Each model run is saved in a folder with a random hash identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1406d5a0-9f10-4a02-bbf1-d907ea2b0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model runs:\n",
      "d46e7b66-9ba1-474f-9142-5dd28be63f50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_runs = os.listdir('p1/training-output/checkpoint')\n",
    "print('Available model runs:')\n",
    "for run in model_runs:\n",
    "    print(run + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc6472-f2fe-4f08-a94c-715809cf674f",
   "metadata": {},
   "source": [
    "Select a model run from the list above and load the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd3728f-99ca-42fb-a121-570ca90e220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = 'd46e7b66-9ba1-474f-9142-5dd28be63f50'  # model run hash identifier\n",
    "\n",
    "## Do not change this ##\n",
    "checkpoint = f'p1/training-output/checkpoint/{model_run}/inference-last.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da79c3-7478-4b8e-9e54-da2e50896c7f",
   "metadata": {},
   "source": [
    "### 5.2) Configure and Run Model Inference\n",
    "Select a target forecast time (valid time) from the testing dataset and set a forecast lead time.\n",
    "\n",
    "You can also create and call a config YAML file that contains the inference settings, however all settings can be easily passed through the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b11141c-affd-4258-a42f-e9c07498ac3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/anemoi/inference/runners/default.py:283: UserWarning: \n",
      "                No post_processors defined. Accumulations will be accumulated from the beginning of the forecast.\n",
      "\n",
      "                🚧🚧🚧 In a future release, the default will be to NOT accumulate from the beginning of the forecast. 🚧🚧🚧\n",
      "                Update your config if you wish to keep accumulating from the beginning.\n",
      "                https://github.com/ecmwf/anemoi-inference/issues/131\n",
      "                \n",
      "  warnings.warn(\n",
      "2025-07-08 17:08:42 INFO Pre processors: []\n",
      "2025-07-08 17:08:42 INFO Accumulating fields []\n",
      "2025-07-08 17:08:42 INFO Post processors: [Accumulate([])]\n",
      "2025-07-08 17:08:42 INFO Using DefaultRunner runner, device=cuda\n",
      "2025-07-08 17:08:42 INFO Input: DatasetInput(('p1/dataset/testing.zarr',), {})\n",
      "2025-07-08 17:08:42 INFO Output: NetCDFOutput(forecast.nc)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX cos_julian_day, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX cos_local_time, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX cos_longitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX hgtsfc_static, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX insolation, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX land_static, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh2m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX pressfc, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX sin_julian_day, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX sin_latitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX sin_local_time, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX sin_longitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp2m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd10m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd10m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO Computed constant forcings: before ['cos_longitude', 'sin_latitude', 'sin_longitude'], after []\n",
      "2025-07-08 17:08:42 INFO Dynamic computed forcing: ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Input state:\n",
      "2025-07-08 17:08:42 INFO   ['cos_julian_day', 'cos_local_time', 'cos_longitude', 'dzdt_225', 'dzdt_275', 'dzdt_325', 'dzdt_375', 'dzdt_425', 'dzdt_475', 'dzdt_525', 'dzdt_575', 'dzdt_625', 'dzdt_675', 'dzdt_725', 'dzdt_775', 'dzdt_825', 'dzdt_875', 'dzdt_925', 'dzdt_975', 'hgtsfc_static', 'insolation', 'land_static', 'log_spfh_225', 'log_spfh_275', 'log_spfh_325', 'log_spfh_375', 'log_spfh_425', 'log_spfh_475', 'log_spfh_525', 'log_spfh_575', 'log_spfh_625', 'log_spfh_675', 'log_spfh_725', 'log_spfh_775', 'log_spfh_825', 'log_spfh_875', 'log_spfh_925', 'log_spfh_975', 'log_spfh2m', 'pressfc', 'sin_julian_day', 'sin_latitude', 'sin_local_time', 'sin_longitude', 'tmp_225', 'tmp_275', 'tmp_325', 'tmp_375', 'tmp_425', 'tmp_475', 'tmp_525', 'tmp_575', 'tmp_625', 'tmp_675', 'tmp_725', 'tmp_775', 'tmp_825', 'tmp_875', 'tmp_925', 'tmp_975', 'tmp2m', 'ugrd_225', 'ugrd_275', 'ugrd_325', 'ugrd_375', 'ugrd_425', 'ugrd_475', 'ugrd_525', 'ugrd_575', 'ugrd_625', 'ugrd_675', 'ugrd_725', 'ugrd_775', 'ugrd_825', 'ugrd_875', 'ugrd_925', 'ugrd_975', 'ugrd10m', 'vgrd_225', 'vgrd_275', 'vgrd_325', 'vgrd_375', 'vgrd_425', 'vgrd_475', 'vgrd_525', 'vgrd_575', 'vgrd_625', 'vgrd_675', 'vgrd_725', 'vgrd_775', 'vgrd_825', 'vgrd_875', 'vgrd_925', 'vgrd_975', 'vgrd10m']\n",
      "2025-07-08 17:08:42 INFO Constant forcings inputs:\n",
      "2025-07-08 17:08:42 INFO Dynamic forcings inputs:\n",
      "2025-07-08 17:08:42 INFO   ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO Boundary forcings inputs:\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Initial forcings:\n",
      "2025-07-08 17:08:42 INFO   Constant forcings inputs:\n",
      "2025-07-08 17:08:42 INFO   Dynamic forcings inputs:\n",
      "2025-07-08 17:08:42 INFO     ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Dynamic forcings input: ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time']) ['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'] ([datetime.datetime(1994, 3, 31, 15, 0), datetime.datetime(1994, 3, 31, 21, 0)])\n",
      "2025-07-08 17:08:42 INFO Expected shape for each input fields: (2, 73728)\n",
      "2025-07-08 17:08:43 INFO Preparing input tensor with shape (2, 95, 73728)\n",
      "2025-07-08 17:08:46 INFO Loading Checkpoint(p1/training-output/checkpoint/d46e7b66-9ba1-474f-9142-5dd28be63f50/inference-last.ckpt): 3 seconds.\n",
      "2025-07-08 17:08:46 INFO Lead time: 12:00:00, time stepping: 6:00:00 Forecasting 2 steps\n",
      "2025-07-08 17:08:47 INFO Forecasting step 6:00:00 (1994-04-01 03:00:00): 0.7 seconds.\n",
      "2025-07-08 17:08:47 INFO Post processor: Accumulate([])\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX hgtsfc_static, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX land_static, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh2m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX pressfc, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp2m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd10m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd10m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO Forecasting step 12:00:00 (1994-04-01 09:00:00): 21.8 milliseconds.\n",
      "2025-07-08 17:08:47 INFO Post processor: Accumulate([])\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX dzdt_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX hgtsfc_static, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX land_static, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX log_spfh2m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX pressfc, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX tmp2m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX ugrd10m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO 🚧🚧🚧🚧🚧🚧 XXXXXX vgrd10m, 2, (73728,)\n"
     ]
    }
   ],
   "source": [
    "forecast_time = '1994-03-31T21'  # valid time [YYYY]-[MM]-[DD]T[HH]\n",
    "lead_time = 12  # hours\n",
    "\n",
    "## Do not change these ##\n",
    "inference_dataset = 'p1/dataset/testing.zarr'\n",
    "output_file = 'forecast.nc'  # output file containing the model forecast\n",
    "\n",
    "!anemoi-inference run checkpoint={checkpoint} date={forecast_time} lead_time={lead_time} input.dataset={inference_dataset} output.netcdf={output_file}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
