{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewjustin/anemoi-workflow/blob/main/anemoi-workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1deeec57-cf88-4f95-92cb-8fd2a1638ce5",
      "metadata": {
        "id": "1deeec57-cf88-4f95-92cb-8fd2a1638ce5"
      },
      "source": [
        "# Anemoi Training Workflow Demo\n",
        "\n",
        "This notebook will guide you through training an AI4NWP model with the Anemoi framework. https://github.com/ecmwf/anemoi-core/tree/main\n",
        "\n",
        "Datasets used for training will be created using the ufs2arco package. https://github.com/NOAA-PSL/ufs2arco/tree/main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0e3243-f89b-4771-be86-880d7bbe5eab",
      "metadata": {
        "id": "9c0e3243-f89b-4771-be86-880d7bbe5eab"
      },
      "source": [
        "# 1) Environment Setup\n",
        "\n",
        "The environment tested with this notebook utilized Python 3.11.13 on Ubuntu 24.04.\n",
        "- **There is no guarantee that this notebook will run error-free using a Python installation on Windows**.\n",
        "\n",
        "We will utilize *pip* for installing required packages. Make sure you have the latest version of *pip* before proceeding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b744034-41ae-4894-853f-924a6ebd41d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b744034-41ae-4894-853f-924a6ebd41d2",
        "outputId": "57f9f0b4-6ba2-48b5-ee3e-4f003e3c836a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48698173-1cc9-427f-8486-1866c6a11b9c",
      "metadata": {
        "id": "48698173-1cc9-427f-8486-1866c6a11b9c"
      },
      "source": [
        "There are several packages that we need to install through pip.\n",
        "- *ufs2arco*: module that will be used to generate the datasets. https://github.com/NOAA-PSL/ufs2arco/tree/main\n",
        "- *anemoi-datasets*: Anemoi package that optimizes and handles datasets. https://anemoi.readthedocs.io/projects/datasets/en/latest/\n",
        "    - Note that you *can* generate datasets with *anemoi-datasets* instead of *ufs2arco*, however this is not recommended.\n",
        "- *anemoi-graphs*: Anemoi package that allows you to design graphs for AI4NWP models. https://anemoi.readthedocs.io/projects/graphs/en/latest/\n",
        "- *anemoi-models*: provides the rest of the Anemoi packages with core model components. https://anemoi.readthedocs.io/projects/models/en/latest/\n",
        "- *anemoi-training*: provides the training functionality for Anemoi. https://anemoi.readthedocs.io/projects/training/en/latest/\n",
        "- *anemoi-inference*: framework for performing model inference with AI4NWP models trained using Anemoi. https://anemoi.readthedocs.io/projects/inference/en/latest/\n",
        "- *flash-attn*: Attention mechanism used in Anemoi's transformer models.\n",
        "  - Flash attention ONLY works on **NVIDIA Ampere GPUs *or newer***. An exhaustive list of Ampere GPUs can be found here: https://en.wikipedia.org/wiki/Ampere_(microarchitecture)#Products_using_Ampere\n",
        "- *mpi4py*: Python bindings for the MPI interface. This is only required if you plan to retrieve data in parallel (**strongly recommended**, especially for very large datasets)\n",
        "- *trimesh*: allows models to utilize triangular meshes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bd9ae2ce-d6e4-425d-bcb9-a7564cf51a2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bd9ae2ce-d6e4-425d-bcb9-a7564cf51a2f",
        "outputId": "11332d32-e39f-4938-9ff6-608400308533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ufs2arco==0.6.0\n",
            "  Downloading ufs2arco-0.6.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting anemoi-datasets==0.5.25\n",
            "  Downloading anemoi_datasets-0.5.25-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting anemoi-graphs==0.6.2\n",
            "  Downloading anemoi_graphs-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting anemoi-models==0.8.1\n",
            "  Downloading anemoi_models-0.8.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting anemoi-training==0.5.1\n",
            "  Downloading anemoi_training-0.5.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting anemoi-inference==0.6.3\n",
            "  Downloading anemoi_inference-0.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.1.tar.gz (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.1.0-cp311-cp311-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting numpy<2.3\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting earthkit-data<0.14.0\n",
            "  Downloading earthkit_data-0.13.9-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting xarray (from ufs2arco==0.6.0)\n",
            "  Downloading xarray-2025.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting cf_xarray (from ufs2arco==0.6.0)\n",
            "  Downloading cf_xarray-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting cftime (from ufs2arco==0.6.0)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting netCDF4 (from ufs2arco==0.6.0)\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting h5netcdf (from ufs2arco==0.6.0)\n",
            "  Downloading h5netcdf-1.6.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting zarr<3 (from ufs2arco==0.6.0)\n",
            "  Downloading zarr-2.18.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting cfgrib (from ufs2arco==0.6.0)\n",
            "  Downloading cfgrib-0.9.15.0-py3-none-any.whl.metadata (55 kB)\n",
            "Collecting bottleneck (from ufs2arco==0.6.0)\n",
            "  Downloading bottleneck-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting dask[complete] (from ufs2arco==0.6.0)\n",
            "  Downloading dask-2025.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fsspec (from ufs2arco==0.6.0)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting s3fs (from ufs2arco==0.6.0)\n",
            "  Downloading s3fs-2025.5.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting gcsfs (from ufs2arco==0.6.0)\n",
            "  Downloading gcsfs-2025.5.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting anemoi-transform>=0.1.10 (from anemoi-datasets==0.5.25)\n",
            "  Downloading anemoi_transform-0.1.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting anemoi-utils>=0.4.21 (from anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading anemoi_utils-0.4.28-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cfunits (from anemoi-datasets==0.5.25)\n",
            "  Downloading cfunits-3.3.7.tar.gz (42 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numcodecs<0.16 (from anemoi-datasets==0.5.25)\n",
            "  Downloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting pyyaml (from anemoi-datasets==0.5.25)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting semantic-version (from anemoi-datasets==0.5.25)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tqdm (from anemoi-datasets==0.5.25)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting zarr<3 (from ufs2arco==0.6.0)\n",
            "  Downloading zarr-2.18.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting hydra-core>=1.3 (from anemoi-graphs==0.6.2)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting matplotlib>=3.6 (from anemoi-graphs==0.6.2)\n",
            "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting networkx>=3.1 (from anemoi-graphs==0.6.2)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting numpy<2.3\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting plotly>=5.19 (from anemoi-graphs==0.6.2)\n",
            "  Downloading plotly-6.2.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting scikit-learn>=1.5 (from anemoi-graphs==0.6.2)\n",
            "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting torch>=2.2 (from anemoi-graphs==0.6.2)\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torch-geometric>=2.3.1 (from anemoi-graphs==0.6.2)\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting typeguard>=4 (from anemoi-graphs==0.6.2)\n",
            "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting einops>=0.6.1 (from anemoi-models==0.8.1)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting datashader>=0.17 (from anemoi-training==0.5.1)\n",
            "  Downloading datashader-0.18.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting mlflow>=2.11.1 (from anemoi-training==0.5.1)\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydantic>=2.9 (from anemoi-training==0.5.1)\n",
            "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting pynvml>=11.5 (from anemoi-training==0.5.1)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyshtools>=4.13 (from anemoi-training==0.5.1)\n",
            "  Downloading pyshtools-4.13.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting pytorch-lightning>=2.1 (from anemoi-training==0.5.1)\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting timm>=0.9.2 (from anemoi-training==0.5.1)\n",
            "  Downloading timm-1.0.17-py3-none-any.whl.metadata (59 kB)\n",
            "Collecting torchinfo>=1.8 (from anemoi-training==0.5.1)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchvision>=0.18 (from anemoi-training==0.5.1)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting aniso8601 (from anemoi-inference==0.6.3)\n",
            "  Downloading aniso8601-10.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Collecting anytree (from anemoi-inference==0.6.3)\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting eccodes>=2.38.3 (from anemoi-inference==0.6.3)\n",
            "  Downloading eccodes-2.42.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from anemoi-inference==0.6.3)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting packaging (from anemoi-inference==0.6.3)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting array-api-compat (from earthkit-data<0.14.0)\n",
            "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting deprecation (from earthkit-data<0.14.0)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting earthkit-meteo>=0.0.1 (from earthkit-data<0.14.0)\n",
            "  Downloading earthkit_meteo-0.4.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting entrypoints (from earthkit-data<0.14.0)\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting filelock (from earthkit-data<0.14.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jinja2 (from earthkit-data<0.14.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema (from earthkit-data<0.14.0)\n",
            "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting lru-dict (from earthkit-data<0.14.0)\n",
            "  Downloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting markdown (from earthkit-data<0.14.0)\n",
            "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting multiurl>=0.3.3 (from earthkit-data<0.14.0)\n",
            "  Downloading multiurl-0.3.5-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pandas (from earthkit-data<0.14.0)\n",
            "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting pdbufr>=0.11 (from earthkit-data<0.14.0)\n",
            "  Downloading pdbufr-0.14.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting deprecated (from numcodecs<0.16->anemoi-datasets==0.5.25)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.2->anemoi-inference==0.6.3)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting asciitree (from zarr<3->ufs2arco==0.6.0)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners (from zarr<3->ufs2arco==0.6.0)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting earthkit-regrid>=0.4 (from anemoi-transform>=0.1.10->anemoi-datasets==0.5.25)\n",
            "  Downloading earthkit_regrid-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting python-dateutil (from anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting rich (from anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting gitpython (from anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting nvsmi (from anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading nvsmi-0.4.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting termcolor (from anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting wcwidth (from anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting attrs>=19.2 (from cfgrib->ufs2arco==0.6.0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting click (from cfgrib->ufs2arco==0.6.0)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting colorcet (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading colorcet-3.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting multipledispatch (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting numba (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting param (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading param-2.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pyct (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting requests (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting scipy (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "Collecting toolz (from datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting earthkit-utils>=0.0.1 (from earthkit-meteo>=0.0.1->earthkit-data<0.14.0)\n",
            "  Downloading earthkit_utils-0.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting cffi (from eccodes>=2.38.3->anemoi-inference==0.6.3)\n",
            "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting findlibs (from eccodes>=2.38.3->anemoi-inference==0.6.3)\n",
            "  Downloading findlibs-0.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading fonttools-4.58.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=3.6->anemoi-graphs==0.6.2)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting Flask<4 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pyarrow<21,>=4.0.0 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting sqlalchemy<3,>=1.4.0 (from mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cloudpickle<4 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading databricks_sdk-0.58.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting starlette<0.48.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting blinker>=1.9.0 (from Flask<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->anemoi-utils[provenance,text]>=0.4.16->anemoi-inference==0.6.3)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->earthkit-data<0.14.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->earthkit-data<0.14.0)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->anemoi-training==0.5.1)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->anemoi-training==0.5.1)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->anemoi-training==0.5.1)\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting six>=1.5 (from python-dateutil->anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn>=1.5->anemoi-graphs==0.6.2)\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.5->anemoi-graphs==0.6.2)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting anyio<5,>=3.6.2 (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.1.1->mlflow>=2.11.1->anemoi-training==0.5.1)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pint (from pdbufr>=0.11->earthkit-data<0.14.0)\n",
            "  Downloading Pint-0.24.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly>=5.19->anemoi-graphs==0.6.2)\n",
            "  Downloading narwhals-1.47.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml>=11.5->anemoi-training==0.5.1)\n",
            "  Downloading nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting astropy>=4.0 (from pyshtools>=4.13->anemoi-training==0.5.1)\n",
            "  Downloading astropy-7.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting pooch>=1.1 (from pyshtools>=4.13->anemoi-training==0.5.1)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pyerfa>=2.0.1.1 (from astropy>=4.0->pyshtools>=4.13->anemoi-training==0.5.1)\n",
            "  Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting astropy-iers-data>=0.2025.4.28.0.37.27 (from astropy>=4.0->pyshtools>=4.13->anemoi-training==0.5.1)\n",
            "  Downloading astropy_iers_data-0.2025.7.14.0.40.29-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.1->pyshtools>=4.13->anemoi-training==0.5.1)\n",
            "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting setuptools (from lightning-utilities>=0.10.0->pytorch-lightning>=2.1->anemoi-training==0.5.1)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting huggingface_hub (from timm>=0.9.2->anemoi-training==0.5.1)\n",
            "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting safetensors (from timm>=0.9.2->anemoi-training==0.5.1)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->anemoi-graphs==0.6.2)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting psutil>=5.8.0 (from torch-geometric>=2.3.1->anemoi-graphs==0.6.2)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pycparser (from cffi->eccodes>=2.38.3->anemoi-inference==0.6.3)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting partd>=1.4.0 (from dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting locket (from partd>=1.4.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting lz4>=4.3.2 (from dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting distributed==2025.7.0 (from dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading distributed-2025.7.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting bokeh>=3.1.0 (from dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading bokeh-3.7.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting msgpack>=1.0.2 (from distributed==2025.7.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2025.7.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2025.7.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading tblib-3.1.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tornado>=6.2.0 (from distributed==2025.7.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting zict>=3.0.0 (from distributed==2025.7.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting xyzservices>=2021.09.1 (from bokeh>=3.1.0->dask[complete]->ufs2arco==0.6.0)\n",
            "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated->numcodecs<0.16->anemoi-datasets==0.5.25)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting decorator>4.1.2 (from gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-auth-oauthlib (from gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-cloud-storage (from gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_cloud_storage-3.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting google-api-core<3.0.0,>=2.15.0 (from google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-cloud-core<3.0.0,>=2.4.2 (from google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-resumable-media<3.0.0,>=2.7.2 (from google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage->gcsfs->ufs2arco==0.6.0)\n",
            "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting h5py (from h5netcdf->ufs2arco==0.6.0)\n",
            "  Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub->timm>=0.9.2->anemoi-training==0.5.1)\n",
            "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->earthkit-data<0.14.0)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema->earthkit-data<0.14.0)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema->earthkit-data<0.14.0)\n",
            "  Downloading rpds_py-0.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->datashader>=0.17->anemoi-training==0.5.1)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting flexcache>=0.3 (from pint->pdbufr>=0.11->earthkit-data<0.14.0)\n",
            "  Downloading flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting flexparser>=0.4 (from pint->pdbufr>=0.11->earthkit-data<0.14.0)\n",
            "  Downloading flexparser-0.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->anemoi-utils>=0.4.21->anemoi-utils[provenance]>=0.4.21->anemoi-datasets==0.5.25)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->ufs2arco==0.6.0)\n",
            "  Downloading aiobotocore-2.23.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->ufs2arco==0.6.0)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.38.28,>=1.38.23 (from aiobotocore<3.0.0,>=2.5.4->s3fs->ufs2arco==0.6.0)\n",
            "  Downloading botocore-1.38.27-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->ufs2arco==0.6.0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Downloading ufs2arco-0.6.0-py3-none-any.whl (63 kB)\n",
            "Downloading anemoi_datasets-0.5.25-py3-none-any.whl (309 kB)\n",
            "Downloading anemoi_graphs-0.6.2-py3-none-any.whl (92 kB)\n",
            "Downloading anemoi_models-0.8.1-py3-none-any.whl (90 kB)\n",
            "Downloading anemoi_training-0.5.1-py3-none-any.whl (252 kB)\n",
            "Downloading anemoi_inference-0.6.3-py3-none-any.whl (175 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading earthkit_data-0.13.9-py3-none-any.whl (363 kB)\n",
            "Downloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading zarr-2.18.4-py3-none-any.whl (210 kB)\n",
            "Downloading mpi4py-4.1.0-cp311-cp311-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.7.0-py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.8/708.8 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anemoi_transform-0.1.13-py3-none-any.whl (75 kB)\n",
            "Downloading anemoi_utils-0.4.28-py3-none-any.whl (90 kB)\n",
            "Downloading cfgrib-0.9.15.0-py3-none-any.whl (48 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading datashader-0.18.1-py3-none-any.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading earthkit_meteo-0.4.1-py3-none-any.whl (56 kB)\n",
            "Downloading earthkit_regrid-0.4.0-py3-none-any.whl (36 kB)\n",
            "Downloading earthkit_utils-0.0.1-py3-none-any.whl (15 kB)\n",
            "Downloading eccodes-2.42.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.58.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading databricks_sdk-0.58.0-py3-none-any.whl (741 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.4/741.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
            "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
            "Downloading starlette-0.47.1-py3-none-any.whl (72 kB)\n",
            "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading multiurl-0.3.5-py3-none-any.whl (21 kB)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdbufr-0.14.0-py3-none-any.whl (52 kB)\n",
            "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.2.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.47.0-py3-none-any.whl (374 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading pyshtools-4.13.1-cp311-cp311-manylinux_2_28_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astropy-7.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astropy_iers_data-0.2025.7.14.0.40.29-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
            "Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.7/738.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading timm-1.0.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m154.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
            "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading xarray-2025.7.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading aniso8601-10.0.1-py2.py3-none-any.whl (52 kB)\n",
            "Downloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "Downloading bottleneck-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "Downloading cf_xarray-0.10.6-py3-none-any.whl (70 kB)\n",
            "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
            "Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorcet-3.1.0-py3-none-any.whl (260 kB)\n",
            "Downloading dask-2025.7.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distributed-2025.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bokeh-3.7.3-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (429 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.1.0-py3-none-any.whl (12 kB)\n",
            "Downloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
            "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading findlibs-0.1.1-py3-none-any.whl (10 kB)\n",
            "Downloading gcsfs-2025.5.1-py2.py3-none-any.whl (36 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Downloading google_cloud_storage-3.2.0-py3-none-any.whl (176 kB)\n",
            "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
            "Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
            "Downloading google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading h5netcdf-1.6.3-py3-none-any.whl (50 kB)\n",
            "Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "Downloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
            "Downloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvsmi-0.4.2-py3-none-any.whl (5.5 kB)\n",
            "Downloading param-2.2.1-py3-none-any.whl (119 kB)\n",
            "Downloading Pint-0.24.4-py3-none-any.whl (302 kB)\n",
            "Downloading flexcache-0.3-py3-none-any.whl (13 kB)\n",
            "Downloading flexparser-0.4-py3-none-any.whl (27 kB)\n",
            "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading s3fs-2025.5.1-py3-none-any.whl (30 kB)\n",
            "Downloading aiobotocore-2.23.0-py3-none-any.whl (84 kB)\n",
            "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.38.27-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m153.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, flash-attn, asciitree, cfunits\n",
            "\u001b[33m  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ae1a1e8aad5407bcc6bcb33c9f87665f86e14e4f7a0148edf2e9eab9df9f0162\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.1-cp311-cp311-linux_x86_64.whl size=126118408 sha256=5a330e5038acaa2309550110731ba580953f76d445a02d9b0d88906d97831db1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/e8/f9/c737fa70cd4a4c0cf9f0d7e3b08b669b69893e7a1591919214\n",
            "\u001b[33m  DEPRECATION: Building 'asciitree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'asciitree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5031 sha256=92d4a86f9c6ab9bff939e74ec59fc09afd993b36c3f6adaa7de26b2a2d894c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c1/da/23077eb3b87d24d6f3852ed1ed1a1ac2d3c885ad6ebd2b4a07\n",
            "  Building wheel for cfunits (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cfunits: filename=cfunits-3.3.7-py3-none-any.whl size=46984 sha256=744229c9004a4ac2dcb6599194f9b8dcbd439e6bba3684fd53b011bfcf59d43b\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/7b/9e/213a65b1feabf835093170c256a80a5eaaf026169f215f3087\n",
            "Successfully built antlr4-python3-runtime flash-attn asciitree cfunits\n",
            "Installing collected packages: wcwidth, sortedcontainers, pytz, nvidia-ml-py, nvidia-cusparselt-cu12, multipledispatch, mpmath, findlibs, asciitree, antlr4-python3-runtime, aniso8601, zipp, zict, xyzservices, wrapt, urllib3, tzdata, typing-extensions, tqdm, tornado, torchinfo, toolz, threadpoolctl, termcolor, tblib, sympy, sqlparse, sniffio, smmap, six, setuptools, semantic-version, safetensors, rpds-py, pyyaml, pyparsing, pynvml, pygments, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, platformdirs, pillow, param, packaging, oauthlib, nvsmi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, multidict, msgpack, mpi4py, mdurl, markupsafe, markdown, lz4, lru-dict, locket, llvmlite, kiwisolver, joblib, jmespath, itsdangerous, idna, hf-xet, h11, greenlet, graphql-core, google-crc32c, fsspec, frozenlist, fonttools, filelock, fasteners, entrypoints, einops, decorator, cycler, colorcet, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, attrs, astropy-iers-data, array-api-compat, anytree, annotated-types, aioitertools, aiohappyeyeballs, yarl, werkzeug, uvicorn, typing-inspection, typeguard, triton, trimesh, sqlalchemy, scipy, rsa, requests, referencing, python-dateutil, pyerfa, pydantic-core, pyct, pyasn1-modules, proto-plus, plotly, partd, omegaconf, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, Mako, lightning-utilities, jinja2, importlib_metadata, h5py, gunicorn, graphql-relay, googleapis-common-protos, google-resumable-media, gitdb, flexparser, flexcache, earthkit-utils, deprecation, deprecated, contourpy, cftime, cffi, bottleneck, anyio, aiosignal, starlette, scikit-learn, rich, requests-oauthlib, pydantic, pooch, pint, pandas, opentelemetry-api, nvidia-cusolver-cu12, numcodecs, netCDF4, multiurl, matplotlib, jsonschema-specifications, hydra-core, huggingface_hub, h5netcdf, graphene, google-auth, gitpython, Flask, eccodes, earthkit-meteo, docker, dask, cfunits, botocore, astropy, alembic, aiohttp, zarr, xarray, torch-geometric, torch, pdbufr, opentelemetry-semantic-conventions, jsonschema, google-auth-oauthlib, google-api-core, fastapi, earthkit-regrid, distributed, databricks-sdk, cfgrib, bokeh, anemoi-utils, aiobotocore, torchvision, torchmetrics, s3fs, pyshtools, opentelemetry-sdk, google-cloud-core, flash-attn, earthkit-data, datashader, cf_xarray, anemoi-models, anemoi-graphs, timm, pytorch-lightning, mlflow-skinny, google-cloud-storage, anemoi-transform, mlflow, gcsfs, anemoi-inference, anemoi-datasets, ufs2arco, anemoi-training\n",
            "\u001b[2K  Attempting uninstall: wcwidth\n",
            "\u001b[2K    Found existing installation: wcwidth 0.2.13\n",
            "\u001b[2K    Uninstalling wcwidth-0.2.13:\n",
            "\u001b[2K      Successfully uninstalled wcwidth-0.2.13\n",
            "\u001b[2K  Attempting uninstall: sortedcontainers\n",
            "\u001b[2K    Found existing installation: sortedcontainers 2.4.0\n",
            "\u001b[2K    Uninstalling sortedcontainers-2.4.0:\n",
            "\u001b[2K      Successfully uninstalled sortedcontainers-2.4.0\n",
            "\u001b[2K  Attempting uninstall: pytz\n",
            "\u001b[2K    Found existing installation: pytz 2025.2\n",
            "\u001b[2K    Uninstalling pytz-2025.2:\n",
            "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-ml-py\n",
            "\u001b[2K    Found existing installation: nvidia-ml-py 12.575.51\n",
            "\u001b[2K    Uninstalling nvidia-ml-py-12.575.51:\n",
            "\u001b[2K      Successfully uninstalled nvidia-ml-py-12.575.51\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "\u001b[2K  Attempting uninstall: multipledispatch\n",
            "\u001b[2K    Found existing installation: multipledispatch 1.0.0\n",
            "\u001b[2K    Uninstalling multipledispatch-1.0.0:\n",
            "\u001b[2K      Successfully uninstalled multipledispatch-1.0.0\n",
            "\u001b[2K  Attempting uninstall: mpmath\n",
            "\u001b[2K    Found existing installation: mpmath 1.3.0\n",
            "\u001b[2K    Uninstalling mpmath-1.3.0:\n",
            "\u001b[2K      Successfully uninstalled mpmath-1.3.0\n",
            "\u001b[2K  Attempting uninstall: antlr4-python3-runtime\n",
            "\u001b[2K    Found existing installation: antlr4-python3-runtime 4.9.3\n",
            "\u001b[2K    Uninstalling antlr4-python3-runtime-4.9.3:\n",
            "\u001b[2K      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
            "\u001b[2K  Attempting uninstall: zipp\n",
            "\u001b[2K    Found existing installation: zipp 3.23.0\n",
            "\u001b[2K    Uninstalling zipp-3.23.0:\n",
            "\u001b[2K      Successfully uninstalled zipp-3.23.0\n",
            "\u001b[2K  Attempting uninstall: zict\n",
            "\u001b[2K    Found existing installation: zict 3.0.0\n",
            "\u001b[2K    Uninstalling zict-3.0.0:\n",
            "\u001b[2K      Successfully uninstalled zict-3.0.0\n",
            "\u001b[2K  Attempting uninstall: xyzservices\n",
            "\u001b[2K    Found existing installation: xyzservices 2025.4.0\n",
            "\u001b[2K    Uninstalling xyzservices-2025.4.0:\n",
            "\u001b[2K      Successfully uninstalled xyzservices-2025.4.0\n",
            "\u001b[2K  Attempting uninstall: wrapt\n",
            "\u001b[2K    Found existing installation: wrapt 1.17.2\n",
            "\u001b[2K    Uninstalling wrapt-1.17.2:\n",
            "\u001b[2K      Successfully uninstalled wrapt-1.17.2\n",
            "\u001b[2K  Attempting uninstall: urllib3\n",
            "\u001b[2K    Found existing installation: urllib3 2.4.0\n",
            "\u001b[2K    Uninstalling urllib3-2.4.0:\n",
            "\u001b[2K      Successfully uninstalled urllib3-2.4.0\n",
            "\u001b[2K  Attempting uninstall: tzdata\n",
            "\u001b[2K    Found existing installation: tzdata 2025.2\n",
            "\u001b[2K    Uninstalling tzdata-2025.2:\n",
            "\u001b[2K      Successfully uninstalled tzdata-2025.2\n",
            "\u001b[2K  Attempting uninstall: typing-extensions\n",
            "\u001b[2K    Found existing installation: typing_extensions 4.14.1\n",
            "\u001b[2K    Uninstalling typing_extensions-4.14.1:\n",
            "\u001b[2K      Successfully uninstalled typing_extensions-4.14.1\n",
            "\u001b[2K  Attempting uninstall: tqdm\n",
            "\u001b[2K    Found existing installation: tqdm 4.67.1\n",
            "\u001b[2K    Uninstalling tqdm-4.67.1:\n",
            "\u001b[2K      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[2K  Attempting uninstall: tornado\n",
            "\u001b[2K    Found existing installation: tornado 6.4.2\n",
            "\u001b[2K    Uninstalling tornado-6.4.2:\n",
            "\u001b[2K      Successfully uninstalled tornado-6.4.2\n",
            "\u001b[2K  Attempting uninstall: toolz\n",
            "\u001b[2K    Found existing installation: toolz 0.12.1\n",
            "\u001b[2K    Uninstalling toolz-0.12.1:\n",
            "\u001b[2K      Successfully uninstalled toolz-0.12.1\n",
            "\u001b[2K  Attempting uninstall: threadpoolctl\n",
            "\u001b[2K    Found existing installation: threadpoolctl 3.6.0\n",
            "\u001b[2K    Uninstalling threadpoolctl-3.6.0:\n",
            "\u001b[2K      Successfully uninstalled threadpoolctl-3.6.0\n",
            "\u001b[2K  Attempting uninstall: termcolor\n",
            "\u001b[2K    Found existing installation: termcolor 3.1.0\n",
            "\u001b[2K    Uninstalling termcolor-3.1.0:\n",
            "\u001b[2K      Successfully uninstalled termcolor-3.1.0\n",
            "\u001b[2K  Attempting uninstall: tblib\n",
            "\u001b[2K    Found existing installation: tblib 3.1.0\n",
            "\u001b[2K    Uninstalling tblib-3.1.0:\n",
            "\u001b[2K      Successfully uninstalled tblib-3.1.0\n",
            "\u001b[2K  Attempting uninstall: sympy\n",
            "\u001b[2K    Found existing installation: sympy 1.13.1\n",
            "\u001b[2K    Uninstalling sympy-1.13.1:\n",
            "\u001b[2K      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[2K  Attempting uninstall: sqlparse\n",
            "\u001b[2K    Found existing installation: sqlparse 0.5.3\n",
            "\u001b[2K    Uninstalling sqlparse-0.5.3:\n",
            "\u001b[2K      Successfully uninstalled sqlparse-0.5.3\n",
            "\u001b[2K  Attempting uninstall: sniffio\n",
            "\u001b[2K    Found existing installation: sniffio 1.3.1\n",
            "\u001b[2K    Uninstalling sniffio-1.3.1:\n",
            "\u001b[2K      Successfully uninstalled sniffio-1.3.1\n",
            "\u001b[2K  Attempting uninstall: smmap\n",
            "\u001b[2K    Found existing installation: smmap 5.0.2\n",
            "\u001b[2K    Uninstalling smmap-5.0.2:\n",
            "\u001b[2K      Successfully uninstalled smmap-5.0.2\n",
            "\u001b[2K  Attempting uninstall: six\n",
            "\u001b[2K    Found existing installation: six 1.17.0\n",
            "\u001b[2K    Uninstalling six-1.17.0:\n",
            "\u001b[2K      Successfully uninstalled six-1.17.0\n",
            "\u001b[2K  Attempting uninstall: setuptools\n",
            "\u001b[2K    Found existing installation: setuptools 75.2.0\n",
            "\u001b[2K    Uninstalling setuptools-75.2.0:\n",
            "\u001b[2K      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[2K  Attempting uninstall: semantic-version\n",
            "\u001b[2K    Found existing installation: semantic-version 2.10.0\n",
            "\u001b[2K    Uninstalling semantic-version-2.10.0:\n",
            "\u001b[2K      Successfully uninstalled semantic-version-2.10.0\n",
            "\u001b[2K  Attempting uninstall: safetensors\n",
            "\u001b[2K    Found existing installation: safetensors 0.5.3\n",
            "\u001b[2K    Uninstalling safetensors-0.5.3:\n",
            "\u001b[2K      Successfully uninstalled safetensors-0.5.3\n",
            "\u001b[2K  Attempting uninstall: rpds-py\n",
            "\u001b[2K    Found existing installation: rpds-py 0.26.0\n",
            "\u001b[2K    Uninstalling rpds-py-0.26.0:\n",
            "\u001b[2K      Successfully uninstalled rpds-py-0.26.0\n",
            "\u001b[2K  Attempting uninstall: pyyaml\n",
            "\u001b[2K    Found existing installation: PyYAML 6.0.2\n",
            "\u001b[2K    Uninstalling PyYAML-6.0.2:\n",
            "\u001b[2K      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[2K  Attempting uninstall: pyparsing\n",
            "\u001b[2K    Found existing installation: pyparsing 3.2.3\n",
            "\u001b[2K    Uninstalling pyparsing-3.2.3:\n",
            "\u001b[2K      Successfully uninstalled pyparsing-3.2.3\n",
            "\u001b[2K  Attempting uninstall: pynvml\n",
            "\u001b[2K    Found existing installation: pynvml 12.0.0\n",
            "\u001b[2K    Uninstalling pynvml-12.0.0:\n",
            "\u001b[2K      Successfully uninstalled pynvml-12.0.0\n",
            "\u001b[2K  Attempting uninstall: pygments\n",
            "\u001b[2K    Found existing installation: Pygments 2.19.2\n",
            "\u001b[2K    Uninstalling Pygments-2.19.2:\n",
            "\u001b[2K      Successfully uninstalled Pygments-2.19.2\n",
            "\u001b[2K  Attempting uninstall: pycparser\n",
            "\u001b[2K    Found existing installation: pycparser 2.22\n",
            "\u001b[2K    Uninstalling pycparser-2.22:\n",
            "\u001b[2K      Successfully uninstalled pycparser-2.22\n",
            "\u001b[2K  Attempting uninstall: pyasn1\n",
            "\u001b[2K    Found existing installation: pyasn1 0.6.1\n",
            "\u001b[2K    Uninstalling pyasn1-0.6.1:\n",
            "\u001b[2K      Successfully uninstalled pyasn1-0.6.1\n",
            "\u001b[2K  Attempting uninstall: pyarrow\n",
            "\u001b[2K    Found existing installation: pyarrow 18.1.0\n",
            "\u001b[2K    Uninstalling pyarrow-18.1.0:\n",
            "\u001b[2K      Successfully uninstalled pyarrow-18.1.0\n",
            "\u001b[2K  Attempting uninstall: psutil\n",
            "\u001b[2K    Found existing installation: psutil 5.9.5\n",
            "\u001b[2K    Uninstalling psutil-5.9.5:\n",
            "\u001b[2K      Successfully uninstalled psutil-5.9.5\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: propcache\n",
            "\u001b[2K    Found existing installation: propcache 0.3.2\n",
            "\u001b[2K    Uninstalling propcache-0.3.2:\n",
            "\u001b[2K      Successfully uninstalled propcache-0.3.2\n",
            "\u001b[2K  Attempting uninstall: platformdirs\n",
            "\u001b[2K    Found existing installation: platformdirs 4.3.8\n",
            "\u001b[2K    Uninstalling platformdirs-4.3.8:\n",
            "\u001b[2K      Successfully uninstalled platformdirs-4.3.8\n",
            "\u001b[2K  Attempting uninstall: pillow\n",
            "\u001b[2K    Found existing installation: pillow 11.2.1\n",
            "\u001b[2K    Uninstalling pillow-11.2.1:\n",
            "\u001b[2K      Successfully uninstalled pillow-11.2.1\n",
            "\u001b[2K  Attempting uninstall: param\n",
            "\u001b[2K    Found existing installation: param 2.2.1\n",
            "\u001b[2K    Uninstalling param-2.2.1:\n",
            "\u001b[2K      Successfully uninstalled param-2.2.1\n",
            "\u001b[2K  Attempting uninstall: packaging\n",
            "\u001b[2K    Found existing installation: packaging 24.2\n",
            "\u001b[2K    Uninstalling packaging-24.2:\n",
            "\u001b[2K      Successfully uninstalled packaging-24.2\n",
            "\u001b[2K  Attempting uninstall: oauthlib\n",
            "\u001b[2K    Found existing installation: oauthlib 3.3.1\n",
            "\u001b[2K    Uninstalling oauthlib-3.3.1:\n",
            "\u001b[2K      Successfully uninstalled oauthlib-3.3.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: networkx\n",
            "\u001b[2K    Found existing installation: networkx 3.5\n",
            "\u001b[2K    Uninstalling networkx-3.5:\n",
            "\u001b[2K      Successfully uninstalled networkx-3.5\n",
            "\u001b[2K  Attempting uninstall: narwhals\n",
            "\u001b[2K    Found existing installation: narwhals 1.46.0\n",
            "\u001b[2K    Uninstalling narwhals-1.46.0:\n",
            "\u001b[2K      Successfully uninstalled narwhals-1.46.0\n",
            "\u001b[2K  Attempting uninstall: multidict\n",
            "\u001b[2K    Found existing installation: multidict 6.6.3\n",
            "\u001b[2K    Uninstalling multidict-6.6.3:\n",
            "\u001b[2K      Successfully uninstalled multidict-6.6.3\n",
            "\u001b[2K  Attempting uninstall: msgpack\n",
            "\u001b[2K    Found existing installation: msgpack 1.1.1\n",
            "\u001b[2K    Uninstalling msgpack-1.1.1:\n",
            "\u001b[2K      Successfully uninstalled msgpack-1.1.1\n",
            "\u001b[2K  Attempting uninstall: mdurl\n",
            "\u001b[2K    Found existing installation: mdurl 0.1.2\n",
            "\u001b[2K    Uninstalling mdurl-0.1.2:\n",
            "\u001b[2K      Successfully uninstalled mdurl-0.1.2\n",
            "\u001b[2K  Attempting uninstall: markupsafe\n",
            "\u001b[2K    Found existing installation: MarkupSafe 3.0.2\n",
            "\u001b[2K    Uninstalling MarkupSafe-3.0.2:\n",
            "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[2K  Attempting uninstall: markdown\n",
            "\u001b[2K    Found existing installation: Markdown 3.8.2\n",
            "\u001b[2K    Uninstalling Markdown-3.8.2:\n",
            "\u001b[2K      Successfully uninstalled Markdown-3.8.2\n",
            "\u001b[2K  Attempting uninstall: locket\n",
            "\u001b[2K    Found existing installation: locket 1.0.0\n",
            "\u001b[2K    Uninstalling locket-1.0.0:\n",
            "\u001b[2K      Successfully uninstalled locket-1.0.0\n",
            "\u001b[2K  Attempting uninstall: llvmlite\n",
            "\u001b[2K    Found existing installation: llvmlite 0.43.0\n",
            "\u001b[2K    Uninstalling llvmlite-0.43.0:\n",
            "\u001b[2K      Successfully uninstalled llvmlite-0.43.0\n",
            "\u001b[2K  Attempting uninstall: kiwisolver\n",
            "\u001b[2K    Found existing installation: kiwisolver 1.4.8\n",
            "\u001b[2K    Uninstalling kiwisolver-1.4.8:\n",
            "\u001b[2K      Successfully uninstalled kiwisolver-1.4.8\n",
            "\u001b[2K  Attempting uninstall: joblib\n",
            "\u001b[2K    Found existing installation: joblib 1.5.1\n",
            "\u001b[2K    Uninstalling joblib-1.5.1:\n",
            "\u001b[2K      Successfully uninstalled joblib-1.5.1\n",
            "\u001b[2K  Attempting uninstall: itsdangerous\n",
            "\u001b[2K    Found existing installation: itsdangerous 2.2.0\n",
            "\u001b[2K    Uninstalling itsdangerous-2.2.0:\n",
            "\u001b[2K      Successfully uninstalled itsdangerous-2.2.0\n",
            "\u001b[2K  Attempting uninstall: idna\n",
            "\u001b[2K    Found existing installation: idna 3.10\n",
            "\u001b[2K    Uninstalling idna-3.10:\n",
            "\u001b[2K      Successfully uninstalled idna-3.10\n",
            "\u001b[2K  Attempting uninstall: hf-xet\n",
            "\u001b[2K    Found existing installation: hf-xet 1.1.5\n",
            "\u001b[2K    Uninstalling hf-xet-1.1.5:\n",
            "\u001b[2K      Successfully uninstalled hf-xet-1.1.5\n",
            "\u001b[2K  Attempting uninstall: h11\n",
            "\u001b[2K    Found existing installation: h11 0.16.0\n",
            "\u001b[2K    Uninstalling h11-0.16.0:\n",
            "\u001b[2K      Successfully uninstalled h11-0.16.0\n",
            "\u001b[2K  Attempting uninstall: greenlet\n",
            "\u001b[2K    Found existing installation: greenlet 3.2.3\n",
            "\u001b[2K    Uninstalling greenlet-3.2.3:\n",
            "\u001b[2K      Successfully uninstalled greenlet-3.2.3\n",
            "\u001b[2K  Attempting uninstall: google-crc32c\n",
            "\u001b[2K    Found existing installation: google-crc32c 1.7.1\n",
            "\u001b[2K    Uninstalling google-crc32c-1.7.1:\n",
            "\u001b[2K      Successfully uninstalled google-crc32c-1.7.1\n",
            "\u001b[2K  Attempting uninstall: fsspec\n",
            "\u001b[2K    Found existing installation: fsspec 2025.3.2\n",
            "\u001b[2K    Uninstalling fsspec-2025.3.2:\n",
            "\u001b[2K      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[2K  Attempting uninstall: frozenlist\n",
            "\u001b[2K    Found existing installation: frozenlist 1.7.0\n",
            "\u001b[2K    Uninstalling frozenlist-1.7.0:\n",
            "\u001b[2K      Successfully uninstalled frozenlist-1.7.0\n",
            "\u001b[2K  Attempting uninstall: fonttools\n",
            "\u001b[2K    Found existing installation: fonttools 4.58.5\n",
            "\u001b[2K    Uninstalling fonttools-4.58.5:\n",
            "\u001b[2K      Successfully uninstalled fonttools-4.58.5\n",
            "\u001b[2K  Attempting uninstall: filelock\n",
            "\u001b[2K    Found existing installation: filelock 3.18.0\n",
            "\u001b[2K    Uninstalling filelock-3.18.0:\n",
            "\u001b[2K      Successfully uninstalled filelock-3.18.0\n",
            "\u001b[2K  Attempting uninstall: entrypoints\n",
            "\u001b[2K    Found existing installation: entrypoints 0.4\n",
            "\u001b[2K    Uninstalling entrypoints-0.4:\n",
            "\u001b[2K      Successfully uninstalled entrypoints-0.4\n",
            "\u001b[2K  Attempting uninstall: einops\n",
            "\u001b[2K    Found existing installation: einops 0.8.1\n",
            "\u001b[2K    Uninstalling einops-0.8.1:\n",
            "\u001b[2K      Successfully uninstalled einops-0.8.1\n",
            "\u001b[2K  Attempting uninstall: decorator\n",
            "\u001b[2K    Found existing installation: decorator 4.4.2\n",
            "\u001b[2K    Uninstalling decorator-4.4.2:\n",
            "\u001b[2K      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[2K  Attempting uninstall: cycler\n",
            "\u001b[2K    Found existing installation: cycler 0.12.1\n",
            "\u001b[2K    Uninstalling cycler-0.12.1:\n",
            "\u001b[2K      Successfully uninstalled cycler-0.12.1\n",
            "\u001b[2K  Attempting uninstall: colorcet\n",
            "\u001b[2K    Found existing installation: colorcet 3.1.0\n",
            "\u001b[2K    Uninstalling colorcet-3.1.0:\n",
            "\u001b[2K      Successfully uninstalled colorcet-3.1.0\n",
            "\u001b[2K  Attempting uninstall: cloudpickle\n",
            "\u001b[2K    Found existing installation: cloudpickle 3.1.1\n",
            "\u001b[2K    Uninstalling cloudpickle-3.1.1:\n",
            "\u001b[2K      Successfully uninstalled cloudpickle-3.1.1\n",
            "\u001b[2K  Attempting uninstall: click\n",
            "\u001b[2K    Found existing installation: click 8.2.1\n",
            "\u001b[2K    Uninstalling click-8.2.1:\n",
            "\u001b[2K      Successfully uninstalled click-8.2.1\n",
            "\u001b[2K  Attempting uninstall: charset_normalizer\n",
            "\u001b[2K    Found existing installation: charset-normalizer 3.4.2\n",
            "\u001b[2K    Uninstalling charset-normalizer-3.4.2:\n",
            "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.2\n",
            "\u001b[2K  Attempting uninstall: certifi\n",
            "\u001b[2K    Found existing installation: certifi 2025.7.9\n",
            "\u001b[2K    Uninstalling certifi-2025.7.9:\n",
            "\u001b[2K      Successfully uninstalled certifi-2025.7.9\n",
            "\u001b[2K  Attempting uninstall: cachetools\n",
            "\u001b[2K    Found existing installation: cachetools 5.5.2\n",
            "\u001b[2K    Uninstalling cachetools-5.5.2:\n",
            "\u001b[2K      Successfully uninstalled cachetools-5.5.2\n",
            "\u001b[2K  Attempting uninstall: blinker\n",
            "\u001b[2K    Found existing installation: blinker 1.9.0\n",
            "\u001b[2K    Uninstalling blinker-1.9.0:\n",
            "\u001b[2K      Successfully uninstalled blinker-1.9.0\n",
            "\u001b[2K  Attempting uninstall: attrs\n",
            "\u001b[2K    Found existing installation: attrs 25.3.0\n",
            "\u001b[2K    Uninstalling attrs-25.3.0:\n",
            "\u001b[2K      Successfully uninstalled attrs-25.3.0\n",
            "\u001b[2K  Attempting uninstall: astropy-iers-data\n",
            "\u001b[2K    Found existing installation: astropy-iers-data 0.2025.7.7.0.39.39\n",
            "\u001b[2K    Uninstalling astropy-iers-data-0.2025.7.7.0.39.39:\n",
            "\u001b[2K      Successfully uninstalled astropy-iers-data-0.2025.7.7.0.39.39\n",
            "\u001b[2K  Attempting uninstall: annotated-types\n",
            "\u001b[2K    Found existing installation: annotated-types 0.7.0\n",
            "\u001b[2K    Uninstalling annotated-types-0.7.0:\n",
            "\u001b[2K      Successfully uninstalled annotated-types-0.7.0\n",
            "\u001b[2K  Attempting uninstall: aiohappyeyeballs\n",
            "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "\u001b[2K  Attempting uninstall: yarl\n",
            "\u001b[2K    Found existing installation: yarl 1.20.1\n",
            "\u001b[2K    Uninstalling yarl-1.20.1:\n",
            "\u001b[2K      Successfully uninstalled yarl-1.20.1\n",
            "\u001b[2K  Attempting uninstall: werkzeug\n",
            "\u001b[2K    Found existing installation: Werkzeug 3.1.3\n",
            "\u001b[2K    Uninstalling Werkzeug-3.1.3:\n",
            "\u001b[2K      Successfully uninstalled Werkzeug-3.1.3\n",
            "\u001b[2K  Attempting uninstall: uvicorn\n",
            "\u001b[2K    Found existing installation: uvicorn 0.35.0\n",
            "\u001b[2K    Uninstalling uvicorn-0.35.0:\n",
            "\u001b[2K      Successfully uninstalled uvicorn-0.35.0\n",
            "\u001b[2K  Attempting uninstall: typing-inspection\n",
            "\u001b[2K    Found existing installation: typing-inspection 0.4.1\n",
            "\u001b[2K    Uninstalling typing-inspection-0.4.1:\n",
            "\u001b[2K      Successfully uninstalled typing-inspection-0.4.1\n",
            "\u001b[2K  Attempting uninstall: typeguard\n",
            "\u001b[2K    Found existing installation: typeguard 4.4.4\n",
            "\u001b[2K    Uninstalling typeguard-4.4.4:\n",
            "\u001b[2K      Successfully uninstalled typeguard-4.4.4\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.2.0\n",
            "\u001b[2K    Uninstalling triton-3.2.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.2.0\n",
            "\u001b[2K  Attempting uninstall: sqlalchemy\n",
            "\u001b[2K    Found existing installation: SQLAlchemy 2.0.41\n",
            "\u001b[2K    Uninstalling SQLAlchemy-2.0.41:\n",
            "\u001b[2K      Successfully uninstalled SQLAlchemy-2.0.41\n",
            "\u001b[2K  Attempting uninstall: scipy\n",
            "\u001b[2K    Found existing installation: scipy 1.15.3\n",
            "\u001b[2K    Uninstalling scipy-1.15.3:\n",
            "\u001b[2K      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[2K  Attempting uninstall: rsa\n",
            "\u001b[2K    Found existing installation: rsa 4.9.1\n",
            "\u001b[2K    Uninstalling rsa-4.9.1:\n",
            "\u001b[2K      Successfully uninstalled rsa-4.9.1\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.3\n",
            "\u001b[2K    Uninstalling requests-2.32.3:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.3\n",
            "\u001b[2K  Attempting uninstall: referencing\n",
            "\u001b[2K    Found existing installation: referencing 0.36.2\n",
            "\u001b[2K    Uninstalling referencing-0.36.2:\n",
            "\u001b[2K      Successfully uninstalled referencing-0.36.2\n",
            "\u001b[2K  Attempting uninstall: python-dateutil\n",
            "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0\n",
            "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:\n",
            "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "\u001b[2K  Attempting uninstall: pyerfa\n",
            "\u001b[2K    Found existing installation: pyerfa 2.0.1.5\n",
            "\u001b[2K    Uninstalling pyerfa-2.0.1.5:\n",
            "\u001b[2K      Successfully uninstalled pyerfa-2.0.1.5\n",
            "\u001b[2K  Attempting uninstall: pydantic-core\n",
            "\u001b[2K    Found existing installation: pydantic_core 2.33.2\n",
            "\u001b[2K    Uninstalling pydantic_core-2.33.2:\n",
            "\u001b[2K      Successfully uninstalled pydantic_core-2.33.2\n",
            "\u001b[2K  Attempting uninstall: pyasn1-modules\n",
            "\u001b[2K    Found existing installation: pyasn1_modules 0.4.2\n",
            "\u001b[2K    Uninstalling pyasn1_modules-0.4.2:\n",
            "\u001b[2K      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "\u001b[2K  Attempting uninstall: proto-plus\n",
            "\u001b[2K    Found existing installation: proto-plus 1.26.1\n",
            "\u001b[2K    Uninstalling proto-plus-1.26.1:\n",
            "\u001b[2K      Successfully uninstalled proto-plus-1.26.1\n",
            "\u001b[2K  Attempting uninstall: plotly\n",
            "\u001b[2K    Found existing installation: plotly 5.24.1\n",
            "\u001b[2K    Uninstalling plotly-5.24.1:\n",
            "\u001b[2K      Successfully uninstalled plotly-5.24.1\n",
            "\u001b[2K  Attempting uninstall: partd\n",
            "\u001b[2K    Found existing installation: partd 1.4.2\n",
            "\u001b[2K    Uninstalling partd-1.4.2:\n",
            "\u001b[2K      Successfully uninstalled partd-1.4.2\n",
            "\u001b[2K  Attempting uninstall: omegaconf\n",
            "\u001b[2K    Found existing installation: omegaconf 2.3.0\n",
            "\u001b[2K    Uninstalling omegaconf-2.3.0:\n",
            "\u001b[2K      Successfully uninstalled omegaconf-2.3.0\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: numba\n",
            "\u001b[2K    Found existing installation: numba 0.60.0\n",
            "\u001b[2K    Uninstalling numba-0.60.0:\n",
            "\u001b[2K      Successfully uninstalled numba-0.60.0\n",
            "\u001b[2K  Attempting uninstall: markdown-it-py\n",
            "\u001b[2K    Found existing installation: markdown-it-py 3.0.0\n",
            "\u001b[2K    Uninstalling markdown-it-py-3.0.0:\n",
            "\u001b[2K      Successfully uninstalled markdown-it-py-3.0.0\n",
            "\u001b[2K  Attempting uninstall: Mako\n",
            "\u001b[2K    Found existing installation: Mako 1.1.3\n",
            "\u001b[2K    Uninstalling Mako-1.1.3:\n",
            "\u001b[2K      Successfully uninstalled Mako-1.1.3\n",
            "\u001b[2K  Attempting uninstall: jinja2\n",
            "\u001b[2K    Found existing installation: Jinja2 3.1.6\n",
            "\u001b[2K    Uninstalling Jinja2-3.1.6:\n",
            "\u001b[2K      Successfully uninstalled Jinja2-3.1.6\n",
            "\u001b[2K  Attempting uninstall: importlib_metadata\n",
            "\u001b[2K    Found existing installation: importlib_metadata 8.7.0\n",
            "\u001b[2K    Uninstalling importlib_metadata-8.7.0:\n",
            "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0\n",
            "\u001b[2K  Attempting uninstall: h5py\n",
            "\u001b[2K    Found existing installation: h5py 3.14.0\n",
            "\u001b[2K    Uninstalling h5py-3.14.0:\n",
            "\u001b[2K      Successfully uninstalled h5py-3.14.0\n",
            "\u001b[2K  Attempting uninstall: googleapis-common-protos\n",
            "\u001b[2K    Found existing installation: googleapis-common-protos 1.70.0\n",
            "\u001b[2K    Uninstalling googleapis-common-protos-1.70.0:\n",
            "\u001b[2K      Successfully uninstalled googleapis-common-protos-1.70.0\n",
            "\u001b[2K  Attempting uninstall: google-resumable-media\n",
            "\u001b[2K    Found existing installation: google-resumable-media 2.7.2\n",
            "\u001b[2K    Uninstalling google-resumable-media-2.7.2:\n",
            "\u001b[2K      Successfully uninstalled google-resumable-media-2.7.2\n",
            "\u001b[2K  Attempting uninstall: gitdb\n",
            "\u001b[2K    Found existing installation: gitdb 4.0.12\n",
            "\u001b[2K    Uninstalling gitdb-4.0.12:\n",
            "\u001b[2K      Successfully uninstalled gitdb-4.0.12\n",
            "\u001b[2K  Attempting uninstall: contourpy\n",
            "\u001b[2K    Found existing installation: contourpy 1.3.2\n",
            "\u001b[2K    Uninstalling contourpy-1.3.2:\n",
            "\u001b[2K      Successfully uninstalled contourpy-1.3.2\n",
            "\u001b[2K  Attempting uninstall: cffi\n",
            "\u001b[2K    Found existing installation: cffi 1.17.1\n",
            "\u001b[2K    Uninstalling cffi-1.17.1:\n",
            "\u001b[2K      Successfully uninstalled cffi-1.17.1\n",
            "\u001b[2K  Attempting uninstall: bottleneck\n",
            "\u001b[2K    Found existing installation: Bottleneck 1.4.2\n",
            "\u001b[2K    Uninstalling Bottleneck-1.4.2:\n",
            "\u001b[2K      Successfully uninstalled Bottleneck-1.4.2\n",
            "\u001b[2K  Attempting uninstall: anyio\n",
            "\u001b[2K    Found existing installation: anyio 4.9.0\n",
            "\u001b[2K    Uninstalling anyio-4.9.0:\n",
            "\u001b[2K      Successfully uninstalled anyio-4.9.0\n",
            "\u001b[2K  Attempting uninstall: aiosignal\n",
            "\u001b[2K    Found existing installation: aiosignal 1.4.0\n",
            "\u001b[2K    Uninstalling aiosignal-1.4.0:\n",
            "\u001b[2K      Successfully uninstalled aiosignal-1.4.0\n",
            "\u001b[2K  Attempting uninstall: starlette\n",
            "\u001b[2K    Found existing installation: starlette 0.46.2\n",
            "\u001b[2K    Uninstalling starlette-0.46.2:\n",
            "\u001b[2K      Successfully uninstalled starlette-0.46.2\n",
            "\u001b[2K  Attempting uninstall: scikit-learn\n",
            "\u001b[2K    Found existing installation: scikit-learn 1.6.1\n",
            "\u001b[2K    Uninstalling scikit-learn-1.6.1:\n",
            "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[2K  Attempting uninstall: rich\n",
            "\u001b[2K    Found existing installation: rich 13.9.4\n",
            "\u001b[2K    Uninstalling rich-13.9.4:\n",
            "\u001b[2K      Successfully uninstalled rich-13.9.4\n",
            "\u001b[2K  Attempting uninstall: requests-oauthlib\n",
            "\u001b[2K    Found existing installation: requests-oauthlib 2.0.0\n",
            "\u001b[2K    Uninstalling requests-oauthlib-2.0.0:\n",
            "\u001b[2K      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "\u001b[2K  Attempting uninstall: pydantic\n",
            "\u001b[2K    Found existing installation: pydantic 2.11.7\n",
            "\u001b[2K    Uninstalling pydantic-2.11.7:\n",
            "\u001b[2K      Successfully uninstalled pydantic-2.11.7\n",
            "\u001b[2K  Attempting uninstall: pooch\n",
            "\u001b[2K    Found existing installation: pooch 1.8.2\n",
            "\u001b[2K    Uninstalling pooch-1.8.2:\n",
            "\u001b[2K      Successfully uninstalled pooch-1.8.2\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: matplotlib\n",
            "\u001b[2K    Found existing installation: matplotlib 3.10.0\n",
            "\u001b[2K    Uninstalling matplotlib-3.10.0:\n",
            "\u001b[2K      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[2K  Attempting uninstall: jsonschema-specifications\n",
            "\u001b[2K    Found existing installation: jsonschema-specifications 2025.4.1\n",
            "\u001b[2K    Uninstalling jsonschema-specifications-2025.4.1:\n",
            "\u001b[2K      Successfully uninstalled jsonschema-specifications-2025.4.1\n",
            "\u001b[2K  Attempting uninstall: huggingface_hub\n",
            "\u001b[2K    Found existing installation: huggingface-hub 0.33.2\n",
            "\u001b[2K    Uninstalling huggingface-hub-0.33.2:\n",
            "\u001b[2K      Successfully uninstalled huggingface-hub-0.33.2\n",
            "\u001b[2K  Attempting uninstall: h5netcdf\n",
            "\u001b[2K    Found existing installation: h5netcdf 1.6.3\n",
            "\u001b[2K    Uninstalling h5netcdf-1.6.3:\n",
            "\u001b[2K      Successfully uninstalled h5netcdf-1.6.3\n",
            "\u001b[2K  Attempting uninstall: google-auth\n",
            "\u001b[2K    Found existing installation: google-auth 2.38.0\n",
            "\u001b[2K    Uninstalling google-auth-2.38.0:\n",
            "\u001b[2K      Successfully uninstalled google-auth-2.38.0\n",
            "\u001b[2K  Attempting uninstall: gitpython\n",
            "\u001b[2K    Found existing installation: GitPython 3.1.44\n",
            "\u001b[2K    Uninstalling GitPython-3.1.44:\n",
            "\u001b[2K      Successfully uninstalled GitPython-3.1.44\n",
            "\u001b[2K  Attempting uninstall: Flask\n",
            "\u001b[2K    Found existing installation: Flask 3.1.1\n",
            "\u001b[2K    Uninstalling Flask-3.1.1:\n",
            "\u001b[2K      Successfully uninstalled Flask-3.1.1\n",
            "\u001b[2K  Attempting uninstall: dask\n",
            "\u001b[2K    Found existing installation: dask 2024.12.1\n",
            "\u001b[2K    Uninstalling dask-2024.12.1:\n",
            "\u001b[2K      Successfully uninstalled dask-2024.12.1\n",
            "\u001b[2K  Attempting uninstall: astropy\n",
            "\u001b[2K    Found existing installation: astropy 7.1.0\n",
            "\u001b[2K    Uninstalling astropy-7.1.0:\n",
            "\u001b[2K      Successfully uninstalled astropy-7.1.0\n",
            "\u001b[2K  Attempting uninstall: aiohttp\n",
            "\u001b[2K    Found existing installation: aiohttp 3.11.15\n",
            "\u001b[2K    Uninstalling aiohttp-3.11.15:\n",
            "\u001b[2K      Successfully uninstalled aiohttp-3.11.15\n",
            "\u001b[2K  Attempting uninstall: xarray\n",
            "\u001b[2K    Found existing installation: xarray 2025.3.1\n",
            "\u001b[2K    Uninstalling xarray-2025.3.1:\n",
            "\u001b[2K      Successfully uninstalled xarray-2025.3.1\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.6.0+cu124\n",
            "\u001b[2K    Uninstalling torch-2.6.0+cu124:\n",
            "\u001b[2K      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[2K  Attempting uninstall: jsonschema\n",
            "\u001b[2K    Found existing installation: jsonschema 4.24.0\n",
            "\u001b[2K    Uninstalling jsonschema-4.24.0:\n",
            "\u001b[2K      Successfully uninstalled jsonschema-4.24.0\n",
            "\u001b[2K  Attempting uninstall: google-auth-oauthlib\n",
            "\u001b[2K    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "\u001b[2K    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "\u001b[2K      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "\u001b[2K  Attempting uninstall: google-api-core\n",
            "\u001b[2K    Found existing installation: google-api-core 2.25.1\n",
            "\u001b[2K    Uninstalling google-api-core-2.25.1:\n",
            "\u001b[2K      Successfully uninstalled google-api-core-2.25.1\n",
            "\u001b[2K  Attempting uninstall: fastapi\n",
            "\u001b[2K    Found existing installation: fastapi 0.116.0\n",
            "\u001b[2K    Uninstalling fastapi-0.116.0:\n",
            "\u001b[2K      Successfully uninstalled fastapi-0.116.0\n",
            "\u001b[2K  Attempting uninstall: distributed\n",
            "\u001b[2K    Found existing installation: distributed 2024.12.1\n",
            "\u001b[2K    Uninstalling distributed-2024.12.1:\n",
            "\u001b[2K      Successfully uninstalled distributed-2024.12.1\n",
            "\u001b[2K  Attempting uninstall: bokeh\n",
            "\u001b[2K    Found existing installation: bokeh 3.7.3\n",
            "\u001b[2K    Uninstalling bokeh-3.7.3:\n",
            "\u001b[2K      Successfully uninstalled bokeh-3.7.3\n",
            "\u001b[2K  Attempting uninstall: torchvision\n",
            "\u001b[2K    Found existing installation: torchvision 0.21.0+cu124\n",
            "\u001b[2K    Uninstalling torchvision-0.21.0+cu124:\n",
            "\u001b[2K      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[2K  Attempting uninstall: google-cloud-core\n",
            "\u001b[2K    Found existing installation: google-cloud-core 2.4.3\n",
            "\u001b[2K    Uninstalling google-cloud-core-2.4.3:\n",
            "\u001b[2K      Successfully uninstalled google-cloud-core-2.4.3\n",
            "\u001b[2K  Attempting uninstall: timm\n",
            "\u001b[2K    Found existing installation: timm 1.0.17\n",
            "\u001b[2K    Uninstalling timm-1.0.17:\n",
            "\u001b[2K      Successfully uninstalled timm-1.0.17\n",
            "\u001b[2K  Attempting uninstall: google-cloud-storage\n",
            "\u001b[2K    Found existing installation: google-cloud-storage 2.19.0\n",
            "\u001b[2K    Uninstalling google-cloud-storage-2.19.0:\n",
            "\u001b[2K      Successfully uninstalled google-cloud-storage-2.19.0\n",
            "\u001b[2K  Attempting uninstall: gcsfs\n",
            "\u001b[2K    Found existing installation: gcsfs 2025.3.2\n",
            "\u001b[2K    Uninstalling gcsfs-2025.3.2:\n",
            "\u001b[2K      Successfully uninstalled gcsfs-2025.3.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223/223\u001b[0m [anemoi-training]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\n",
            "rapids-dask-dependency 25.2.0 requires dask==2024.12.1, but you have dask 2025.7.0 which is incompatible.\n",
            "rapids-dask-dependency 25.2.0 requires distributed==2024.12.1, but you have distributed 2025.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langchain-core 0.3.68 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "pylibcudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "dask-expr 1.1.21 requires dask==2024.12.1, but you have dask 2025.7.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "plotnine 0.14.6 requires scipy<1.16.0,>=1.8.0, but you have scipy 1.16.0 which is incompatible.\n",
            "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.102.0 requires google-cloud-storage<3.0.0,>=1.32.0, but you have google-cloud-storage 3.2.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-3.1.1 Mako-1.3.10 aiobotocore-2.23.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aioitertools-0.12.0 aiosignal-1.4.0 alembic-1.16.4 anemoi-datasets-0.5.25 anemoi-graphs-0.6.2 anemoi-inference-0.6.3 anemoi-models-0.8.1 anemoi-training-0.5.1 anemoi-transform-0.1.13 anemoi-utils-0.4.28 aniso8601-10.0.1 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.9.0 anytree-2.13.0 array-api-compat-1.12.0 asciitree-0.3.3 astropy-7.1.0 astropy-iers-data-0.2025.7.14.0.40.29 attrs-25.3.0 blinker-1.9.0 bokeh-3.7.3 botocore-1.38.27 bottleneck-1.5.0 cachetools-5.5.2 certifi-2025.7.14 cf_xarray-0.10.6 cffi-1.17.1 cfgrib-0.9.15.0 cftime-1.6.4.post1 cfunits-3.3.7 charset_normalizer-3.4.2 click-8.2.1 cloudpickle-3.1.1 colorcet-3.1.0 contourpy-1.3.2 cycler-0.12.1 dask-2025.7.0 databricks-sdk-0.58.0 datashader-0.18.1 decorator-5.2.1 deprecated-1.2.18 deprecation-2.1.0 distributed-2025.7.0 docker-7.1.0 earthkit-data-0.13.9 earthkit-meteo-0.4.1 earthkit-regrid-0.4.0 earthkit-utils-0.0.1 eccodes-2.42.0 einops-0.8.1 entrypoints-0.4 fastapi-0.116.1 fasteners-0.19 filelock-3.18.0 findlibs-0.1.1 flash-attn-2.8.1 flexcache-0.3 flexparser-0.4 fonttools-4.58.5 frozenlist-1.7.0 fsspec-2025.5.1 gcsfs-2025.5.1 gitdb-4.0.12 gitpython-3.1.44 google-api-core-2.25.1 google-auth-2.40.3 google-auth-oauthlib-1.2.2 google-cloud-core-2.4.3 google-cloud-storage-3.2.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.3 gunicorn-23.0.0 h11-0.16.0 h5netcdf-1.6.3 h5py-3.14.0 hf-xet-1.1.5 huggingface_hub-0.33.4 hydra-core-1.3.2 idna-3.10 importlib_metadata-8.7.0 itsdangerous-2.2.0 jinja2-3.1.6 jmespath-1.0.1 joblib-1.5.1 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 kiwisolver-1.4.8 lightning-utilities-0.14.3 llvmlite-0.44.0 locket-1.0.0 lru-dict-1.3.0 lz4-4.4.4 markdown-3.8.2 markdown-it-py-3.0.0 markupsafe-3.0.2 matplotlib-3.10.3 mdurl-0.1.2 mlflow-3.1.1 mlflow-skinny-3.1.1 mpi4py-4.1.0 mpmath-1.3.0 msgpack-1.1.1 multidict-6.6.3 multipledispatch-1.0.0 multiurl-0.3.5 narwhals-1.47.0 netCDF4-1.7.2 networkx-3.5 numba-0.61.2 numcodecs-0.15.1 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-ml-py-12.575.51 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 nvsmi-0.4.2 oauthlib-3.3.1 omegaconf-2.3.0 opentelemetry-api-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 packaging-25.0 pandas-2.3.1 param-2.2.1 partd-1.4.2 pdbufr-0.14.0 pillow-11.3.0 pint-0.24.4 platformdirs-4.3.8 plotly-6.2.0 pooch-1.8.2 propcache-0.3.2 proto-plus-1.26.1 protobuf-6.31.1 psutil-7.0.0 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.22 pyct-0.5.0 pydantic-2.11.7 pydantic-core-2.33.2 pyerfa-2.0.1.5 pygments-2.19.2 pynvml-12.0.0 pyparsing-3.2.3 pyshtools-4.13.1 python-dateutil-2.9.0.post0 pytorch-lightning-2.5.2 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.4 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.26.0 rsa-4.9.1 s3fs-2025.5.1 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 semantic-version-2.10.0 setuptools-80.9.0 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 sortedcontainers-2.4.0 sqlalchemy-2.0.41 sqlparse-0.5.3 starlette-0.47.1 sympy-1.14.0 tblib-3.1.0 termcolor-3.1.0 threadpoolctl-3.6.0 timm-1.0.17 toolz-1.0.0 torch-2.7.1 torch-geometric-2.6.1 torchinfo-1.8.0 torchmetrics-1.7.4 torchvision-0.22.1 tornado-6.5.1 tqdm-4.67.1 trimesh-4.7.0 triton-3.3.1 typeguard-4.4.4 typing-extensions-4.14.1 typing-inspection-0.4.1 tzdata-2025.2 ufs2arco-0.6.0 urllib3-2.5.0 uvicorn-0.35.0 wcwidth-0.2.13 werkzeug-3.1.3 wrapt-1.17.2 xarray-2025.7.1 xyzservices-2025.4.0 yarl-1.20.1 zarr-2.18.4 zict-3.0.0 zipp-3.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "decorator",
                  "google",
                  "importlib_metadata",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "packaging",
                  "pkg_resources",
                  "platformdirs",
                  "psutil",
                  "pydevd_plugins",
                  "pyparsing",
                  "six",
                  "tornado",
                  "wcwidth",
                  "zipp"
                ]
              },
              "id": "d9e9b78b17ab4f77892807e4ed3e5bfb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install ufs2arco==0.6.0 anemoi-datasets==0.5.25 anemoi-graphs==0.6.2 anemoi-models==0.8.1 anemoi-training==0.5.1 anemoi-inference==0.6.3 flash-attn mpi4py trimesh 'numpy<2.3' 'earthkit-data<0.14.0' --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5f2d5fa-e962-4bce-8ff3-c03ec072addc",
      "metadata": {
        "id": "b5f2d5fa-e962-4bce-8ff3-c03ec072addc"
      },
      "source": [
        "# 2) Build Dataset Recipes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ffbde1-358c-4dab-afec-c86294a7cfcc",
      "metadata": {
        "id": "a6ffbde1-358c-4dab-afec-c86294a7cfcc"
      },
      "source": [
        "Datasets for Anemoi are created using the ufs2arco package: https://github.com/NOAA-PSL/ufs2arco/tree/main\n",
        "\n",
        "YAML files containing a 'recipe' for the dataset can be called to generate the datasets.\n",
        "\n",
        "You can create a single, large dataset for training, validation, and testing, or you can separate these into their own datasets.\n",
        "\n",
        "We will walk through the process of creating a recipe YAML file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7f199e-1771-42d3-89aa-2fa7e191846b",
      "metadata": {
        "id": "7a7f199e-1771-42d3-89aa-2fa7e191846b"
      },
      "source": [
        "## 2.1) Define data mover\n",
        "\n",
        "As the name suggests, the data mover will be used to move data from a remote location to some local directory. There are two datamovers that can be used: 'datamover' and 'mpidatamover' (requires *mpi4py* package). The only difference between these is that 'mpidatamover' has the ability to utilize multiple processor threads, allowing data to be retrieved in parallel.\n",
        "\n",
        "The data mover is defined in the YAML recipe with the **mover.name** parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d923b8-96e6-41c6-99e7-81010be17502",
      "metadata": {
        "id": "36d923b8-96e6-41c6-99e7-81010be17502"
      },
      "outputs": [],
      "source": [
        "mover:\n",
        "    name: mpidatamover"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d683984c-1761-4490-b89b-6f903a6ff177",
      "metadata": {
        "id": "d683984c-1761-4490-b89b-6f903a6ff177"
      },
      "source": [
        "## 2.2) Define directories\n",
        "\n",
        "There are three directory parameters that must be specified in the YAML file:\n",
        "- **directories.zarr**: directory for the dataset in zarr format\n",
        "- **directories.cache**: directory for dataset cache\n",
        "- **directories.logs**: directory for logs showing dataset progress. These logs can be useful for monitoring dataset progress and debugging\n",
        "\n",
        "Note that recursive directory structures will automatically be created if they do not already exist.\n",
        "\n",
        "An example implementation in a YAML recipe is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b15a79-be97-4143-8998-a8b1951f5bc6",
      "metadata": {
        "id": "45b15a79-be97-4143-8998-a8b1951f5bc6"
      },
      "outputs": [],
      "source": [
        "directories:\n",
        "  zarr: p1/dataset/training.zarr\n",
        "  cache: p1/dataset/cache\n",
        "  logs: p1/dataset/logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248f3a47-ae80-4ba2-a5f6-1b9263dbc69c",
      "metadata": {
        "id": "248f3a47-ae80-4ba2-a5f6-1b9263dbc69c"
      },
      "source": [
        "## 2.3) Define dataset configuration\n",
        "\n",
        "The dataset configuration will be within **source**.\n",
        "\n",
        "### 2.3.1) Data source, time window, ensemble member selection\n",
        "\n",
        "Choose the data source and time window you would like to use. The parameters required for this are as follows:\n",
        "- **source.name**: name of the dataset\n",
        "- **source.uri**: URI of the dataset\n",
        "- **source.time.start**: beginning of the desired time window with format YYYY-MM-DD[T]HH\n",
        "- **source.time.end**: end of the time window with format YYYY-MM-DD[T]HH\n",
        "- **source.time.freq**: timestep frequency\n",
        "\n",
        "If your dataset has forecast hours (e.g., GFS), you can specify desired forecast hours:\n",
        "- **source.fh.start**: beginning forecast hour\n",
        "- **source.fh.end**: end forecast hour\n",
        "- **source.fh.step**: forecast hour step/interval\n",
        "\n",
        "If your dataset has ensemble members (e.g., GEFS), you can retrieve specific ensemble members:\n",
        "- **source.member.start**: beginning member number\n",
        "- **source.member.end**: end member number\n",
        "- **source.member.step**: member number step/interval\n",
        "\n",
        "An example implementation in a YAML recipe is shown below. Note that we will add more **source** parameters in subsequent steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae845ff-24c7-4846-a68e-01b753121dc8",
      "metadata": {
        "id": "bae845ff-24c7-4846-a68e-01b753121dc8"
      },
      "outputs": [],
      "source": [
        "source:\n",
        "  name: gcs_replay_atmosphere\n",
        "  uri: gs://noaa-ufs-gefsv13replay/ufs-hr1/0.25-degree-subsampled/03h-freq/zarr/fv3.zarr\n",
        "  time:\n",
        "    start: 1994-01-01T00\n",
        "    end: 1994-01-31T21\n",
        "    freq: 3h"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a55acd-b6f3-4363-90fe-877f1b7b3e30",
      "metadata": {
        "id": "13a55acd-b6f3-4363-90fe-877f1b7b3e30"
      },
      "source": [
        "### 2.3.2) Variables\n",
        "\n",
        "All variables are defined with the **source.variables** parameter in the recipe YAML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417b67e5-acf3-41b8-aa77-c6ac7e08f7e1",
      "metadata": {
        "id": "417b67e5-acf3-41b8-aa77-c6ac7e08f7e1"
      },
      "outputs": [],
      "source": [
        "source:\n",
        "  name: gcs_replay_atmosphere\n",
        "  uri: gs://noaa-ufs-gefsv13replay/ufs-hr1/0.25-degree-subsampled/03h-freq/zarr/fv3.zarr\n",
        "  time:\n",
        "    start: 1994-01-01T00\n",
        "    end: 1994-01-31T21\n",
        "    freq: 3h\n",
        "\n",
        "  variables:\n",
        "    - tmp2m\n",
        "    - spfh2m"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816d308b-f50a-49fe-9133-a638f87dac36",
      "metadata": {
        "id": "816d308b-f50a-49fe-9133-a638f87dac36"
      },
      "source": [
        "### 2.3.3) Pressure Levels\n",
        "\n",
        "Pressure levels can be explicitly defined, or you can select a set of pressure levels through slicing in the recipe YAML.\n",
        "- **source.levels**: list of all desired pressure levels\n",
        "- **source.slice.sel.levels**: retrieve a 'slice' of all pressure levels between two values (e.g., [200, 1000] grabs all pressure levels between 1000 and 250 hPa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420719a8-44e9-40b4-a98f-7261ad29ceda",
      "metadata": {
        "id": "420719a8-44e9-40b4-a98f-7261ad29ceda"
      },
      "outputs": [],
      "source": [
        "source:\n",
        "  name: gcs_replay_atmosphere\n",
        "  uri: gs://noaa-ufs-gefsv13replay/ufs-hr1/0.25-degree-subsampled/03h-freq/zarr/fv3.zarr\n",
        "  time:\n",
        "    start: 1994-01-01T00\n",
        "    end: 1994-01-31T21\n",
        "    freq: 3h\n",
        "\n",
        "  variables:\n",
        "    - tmp2m\n",
        "    - spfh2m\n",
        "\n",
        "  slices:\n",
        "    sel:\n",
        "      level: [200, 1000]  # hPa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8277e212-049e-45ec-94ab-e8452f020584",
      "metadata": {
        "id": "8277e212-049e-45ec-94ab-e8452f020584"
      },
      "source": [
        "### 2.3.4) Coordinates and Selecting Subdomains\n",
        "\n",
        "By default, all lat/lon points in the desired dataset will be obtained and no arguments are required to acquire the entire grid. Lat/lon coordinates in a subdomain can be explicitly defined, or you can select sets of coordinates through slicing in the recipe YAML.\n",
        "- **source.longitude**: list of all desired longitude points\n",
        "- **source.latitude**: list of all desired latitude points\n",
        "- **source.slice.sel.longitude**: retrieve a slice of all longitudes within a range (e.g., [200, 300] grabs all longitudes between 200 and 300 degrees east, using the 360 degree system)\n",
        "- **source.slice.sel.latitude**: retrieve a slice of all latitude values (e.g., [51, 25] grabs all latitudes between 25 and 51 degrees north)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "009419c4-2b5c-40e9-badc-6c6148828531",
      "metadata": {
        "id": "009419c4-2b5c-40e9-badc-6c6148828531"
      },
      "outputs": [],
      "source": [
        "source:\n",
        "  name: gcs_replay_atmosphere\n",
        "  uri: gs://noaa-ufs-gefsv13replay/ufs-hr1/0.25-degree-subsampled/03h-freq/zarr/fv3.zarr\n",
        "  time:\n",
        "    start: 1994-01-01T00\n",
        "    end: 1994-01-31T21\n",
        "    freq: 3h\n",
        "\n",
        "  variables:\n",
        "    - tmp2m\n",
        "    - spfh2m\n",
        "\n",
        "  slices:\n",
        "    sel:\n",
        "      level: [200, 1000]  # hPa\n",
        "      latitude: [53, 21]\n",
        "      longitude: [225, 300]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e20523-5361-4544-b1fa-bb7b5524b882",
      "metadata": {
        "id": "86e20523-5361-4544-b1fa-bb7b5524b882"
      },
      "source": [
        "### 2.3.5) Configure Outputs\n",
        "\n",
        "All of the outputs in the recipe YAML are done in the **target** section.\n",
        "\n",
        "- **target.name**: target name (unsure of the exact purpose)\n",
        "- **target.sort_channels_by_levels**: setting this to True will sort the channels by pressure level\n",
        "- **target.rename**: allows you to rename variables or coordinates (example usage below)\n",
        "- **target.chunks**: configure chunks by coordinates (example usage below)\n",
        "- **target.forcings**: list of forcing variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035aab77-e860-4076-b406-654023ed14ba",
      "metadata": {
        "id": "035aab77-e860-4076-b406-654023ed14ba"
      },
      "outputs": [],
      "source": [
        "target:\n",
        "  name: forecast\n",
        "  sort_channels_by_levels: True\n",
        "  rename:\n",
        "    level: pressure  # rename 'level' to 'pressure'\n",
        "\n",
        "  chunks:\n",
        "    time: 1  # one timestep per chunk\n",
        "    variable: -1  # undefined (all variables in one chunk)\n",
        "    ensemble: 1  # one ensemble member per chunk\n",
        "\n",
        "  forcings:\n",
        "    - cos_latitude\n",
        "    - sin_latitude\n",
        "    - cos_longitude\n",
        "    - sin_longitude\n",
        "    - cos_julian_day\n",
        "    - sin_julian_day\n",
        "    - cos_local_time\n",
        "    - sin_local_time\n",
        "    - cos_solar_zenith_angle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd0951d-33ba-42dd-a60e-5d81ebf36dd5",
      "metadata": {
        "id": "bbd0951d-33ba-42dd-a60e-5d81ebf36dd5"
      },
      "source": [
        "### 2.3.6) Transforms\n",
        "\n",
        "One neat feature of Anemoi is its support for data transformations prior to saving, all of which is done in the **transforms** section. You can perform mathematical operations on a variable(s) in order to get the desired units.\n",
        "\n",
        "- **transforms.divide**: divide a specified variable by some value (example in the cell below)\n",
        "- **transforms.multiply**: multiple a specified variable by some value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871a95fe-cafd-4248-830a-71c30e7bfbb7",
      "metadata": {
        "id": "871a95fe-cafd-4248-830a-71c30e7bfbb7",
        "outputId": "1e10aabb-2585-41ef-c8bf-920859bff867"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (836770422.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtransforms:\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "transforms:\n",
        "  divide:\n",
        "    geopotential_at_surface: 9.80665  # converts geopotential (m2/s2) to geopotential height (m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a8248ae-882c-4865-9006-e3610b7b8dfe",
      "metadata": {
        "id": "8a8248ae-882c-4865-9006-e3610b7b8dfe"
      },
      "source": [
        "## 2.4) Generate datasets with ufs2arco\n",
        "\n",
        "ufs2arco is used to build the datasets. You can keep training, validation, and testing datasets as the same file and select time windows from the zarr file, or you can make separate zarr files for each dataset. Separating dataset files might come with costs and benefits, but this is largely up to user preference.\n",
        "\n",
        "Given a recipe *training.yaml*, you can generate the dataset with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56e0581-25f9-4c46-8479-fc32d384cd8b",
      "metadata": {
        "id": "f56e0581-25f9-4c46-8479-fc32d384cd8b"
      },
      "outputs": [],
      "source": [
        "!ufs2arco training.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205f4a5f-bfe5-444c-8192-24dff163d48d",
      "metadata": {
        "id": "205f4a5f-bfe5-444c-8192-24dff163d48d"
      },
      "source": [
        "# 3) Generate and Modify Config Files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a69f2e1-ae5b-43ec-aac8-52bf948b8c91",
      "metadata": {
        "id": "2a69f2e1-ae5b-43ec-aac8-52bf948b8c91"
      },
      "source": [
        "## 3.1) Generate Config Files\n",
        "\n",
        "Anemoi has a command that generates some config files which can be utilized during model training.\n",
        "\n",
        "Note that these generated files have **a lot** of parameters that should be modified in order to streamline your model training workflow.\n",
        "\n",
        "Run the command below and **carefully** read the instructions/documentation in this sections 3.2 - 3.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de01ad47-a98e-4428-b12f-d5b3a84f9bad",
      "metadata": {
        "id": "de01ad47-a98e-4428-b12f-d5b3a84f9bad"
      },
      "outputs": [],
      "source": [
        "!anemoi-training config generate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6455de1-b5e3-420d-aa3e-58eaa497776a",
      "metadata": {
        "id": "f6455de1-b5e3-420d-aa3e-58eaa497776a"
      },
      "source": [
        "## 3.2) Define batch sizes and configure datasets\n",
        "\n",
        "Batch sizes must be defined for each dataset. The default *dataloader* file *dataloader/native_grid.yaml* has pre-defined batch sizes, however these can be overriden in *config.yaml*.\n",
        "- **dataloader.batch_size.training**: training dataset batch size\n",
        "- **dataloader.batch_size.validation**: validation dataset batch size\n",
        "- **dataloader.batch_size.test**: testing dataset batch size\n",
        "\n",
        "For each dataset, the dataset path and start and end dates need to be specified.\n",
        "- **dataloader.training.dataset**: full path to the training dataset\n",
        "- **dataloader.training.start**: start date for training dataset (YYYY-MM-DD)\n",
        "- **dataloader.training.end**: end date for training dataset (YYYY-MM-DD)\n",
        "- **dataloader.validation.dataset**: full path to the validation dataset\n",
        "- **dataloader.validation.start**: start date for validation dataset (YYYY-MM-DD)\n",
        "- **dataloader.validation.end**: end date for validation dataset (YYYY-MM-DD)\n",
        "- **dataloader.test.dataset**: full path to the test dataset\n",
        "- **dataloader.test.start**: start date for test dataset (YYYY-MM-DD)\n",
        "- **dataloader.test.end**: end date for test dataset (YYYY-MM-DD)\n",
        "\n",
        "Example implementation in *config.yaml*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1d45ee-0e0f-401a-8ecc-5e91cdb662e4",
      "metadata": {
        "id": "cb1d45ee-0e0f-401a-8ecc-5e91cdb662e4"
      },
      "outputs": [],
      "source": [
        "dataloader:\n",
        "  batch_size:\n",
        "    training: 2\n",
        "    validation: 2\n",
        "    test: 2\n",
        "  training:\n",
        "    dataset: ${hardware.paths.data}/training.zarr\n",
        "    start: 1994-01-01\n",
        "    end: 1994-01-31\n",
        "  validation:\n",
        "    dataset: ${hardware.paths.data}/validation.zarr\n",
        "    start: 1994-02-01\n",
        "    end: 1994-02-28\n",
        "  test:\n",
        "    dataset: ${hardware.paths.data}/testing.zarr\n",
        "    start: 1994-03-01\n",
        "    end: 1994-03-31"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44a49d4d-20c0-4380-bccf-d22263497f56",
      "metadata": {
        "id": "44a49d4d-20c0-4380-bccf-d22263497f56"
      },
      "source": [
        "## 3.3) Configure GPUs and Paths\n",
        "\n",
        "One of the most important steps for running the Anemoi framework is configuring paths. At the top of *config.yaml*, the 'hardware' parameter should be set to 'example'. This calls the default settings in *hardware/example.yaml*, however the **data** path is not specified in the *example* yaml. In addition, you may want to specify different directories for storing outputs and model graphs.\n",
        "\n",
        "- **hardware.paths.output**: directory for the outputs (checkpoints, plots, etc.). Directory structure will be created if it does not already exist.\n",
        "- **hardware.paths.data**: directory for the datasets generated with ufs2arco.\n",
        "- **hardware.paths.graph**: directory for the model graph.\n",
        "\n",
        "The name of the zarr file containing the training dataset must also be specified.\n",
        "- **hardware.files.dataset**: name of the training dataset zarr file (do not include absolute path with directory structure)\n",
        "\n",
        "You can also specify the number of GPUs to use for each model with the **hardware.num_gpus_per_model** parameter.\n",
        "\n",
        "An example implementation in *config.yaml* is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041e2885-3cb3-4f68-bf83-4bd7ff5d65f0",
      "metadata": {
        "id": "041e2885-3cb3-4f68-bf83-4bd7ff5d65f0"
      },
      "outputs": [],
      "source": [
        "hardware:\n",
        "\n",
        "  num_gpus_per_model: 1\n",
        "\n",
        "  paths:\n",
        "    output: p1/training-output/\n",
        "    data: p1/dataset\n",
        "    graph: p1/graph\n",
        "\n",
        "  files:\n",
        "    dataset: training.zarr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "852ed49c-d159-4b4b-8751-19d78432b833",
      "metadata": {
        "id": "852ed49c-d159-4b4b-8751-19d78432b833"
      },
      "source": [
        "## 3.4) Configure Model Training\n",
        "\n",
        "There are a few parameters that should be specified in the main *config.yaml* file so model training configurations can be easily modified.\n",
        "\n",
        "At the top of *config.yaml*, you will probably see a 'training' parameter that is set to 'default'. This calls training configuration settings in the *training/default.yaml* file. All of these settings can be overriden in *config.yaml*.\n",
        "\n",
        "Here are some useful training parameters to include in *config.yaml*:\n",
        "- **training.max_epochs**: specifies the maximum number of epochs for model training. Training will stop if this limit is reached.\n",
        "- **training.max_steps**: specifies the maximum number of total steps for model training (*not steps per epoch*). Training will stop if this limit is reached.\n",
        "- **training.lr.rate**: starting learning rate\n",
        "- **training.lr.min**: minimum learning rate\n",
        "\n",
        "An example implementation in *config.yaml* with the aforementioned parameters is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf1895f-b515-4751-820e-8700917cd080",
      "metadata": {
        "id": "7bf1895f-b515-4751-820e-8700917cd080"
      },
      "outputs": [],
      "source": [
        "training:\n",
        "  max_epochs: 500\n",
        "  max_steps: 10000\n",
        "  lr:\n",
        "    rate: 1e-4\n",
        "    min: 3e-7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d8c525-c0f6-481c-b7cc-978cd37b2ace",
      "metadata": {
        "id": "10d8c525-c0f6-481c-b7cc-978cd37b2ace"
      },
      "source": [
        "## 3.5) Configure Diagnostics\n",
        "\n",
        "During training, it is useful to plot sample model predictions and log other information pertaining to the model output/performance in order to get a good idea if your model is 'working' as intended.\n",
        "\n",
        "In the *config.yaml* file, the default file for diagnostics is *diagnostics/evaluation.yaml*. There are a couple empty fields that we will need to define in the following steps.\n",
        "\n",
        "### 3.5.1) Performance Logging\n",
        "\n",
        "For now, we will disable Weights and Biases for performance logging (though you may want to configure a WandB workflow in the future). This can be done by setting the **diagnostics.log.wandb.entity** parameter to 'null'.\n",
        "\n",
        "We will also disable the MLflow tracking server by setting **diagnostics.log.mlflow.tracking_uri** to 'null'.\n",
        "\n",
        "An example implementation in *config.yaml* is shown below. Note that we will continue to modify **diagnostics** in later steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ee8437-e6a7-43c7-bd06-98aaccd88d8d",
      "metadata": {
        "id": "59ee8437-e6a7-43c7-bd06-98aaccd88d8d"
      },
      "outputs": [],
      "source": [
        "diagnostics:\n",
        "  log:\n",
        "    wandb:\n",
        "      entity: null\n",
        "    mlflow:\n",
        "      tracking_uri: null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae6c6d9-5db9-4d0a-b35f-52e13402f25c",
      "metadata": {
        "id": "1ae6c6d9-5db9-4d0a-b35f-52e13402f25c"
      },
      "source": [
        "### 3.5.2) Plotting\n",
        "\n",
        "With the default settings in *diagnostics/evaluation.yaml*, the following plots will be produced at user-defined frequencies for specified variables:\n",
        "* Spatial plots of model predictions and errors\n",
        "* Histograms showing binned model predictions and errors for **every** variable in a single plot\n",
        "\n",
        "The frequency of plotting can be modified directly in *config.yaml* with the following parameters:\n",
        "* **diagnostics.plot.frequency.epoch**: plot frequency in epochs\n",
        "* **diagnostics.plot.frequency.batch**: plot frequency in batches\n",
        "\n",
        "Adding these to **diagnostics** in *config.yaml*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd14c0af-a659-4e3c-8470-496084e99d03",
      "metadata": {
        "id": "fd14c0af-a659-4e3c-8470-496084e99d03"
      },
      "outputs": [],
      "source": [
        "diagnostics:\n",
        "  log:\n",
        "    wandb:\n",
        "      entity: null\n",
        "    mlflow:\n",
        "      tracking_uri: null\n",
        "  plot:\n",
        "    frequency:\n",
        "      epoch: 5\n",
        "      batch: 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa01aa95-30a3-499e-bd12-5c415a58311f",
      "metadata": {
        "id": "fa01aa95-30a3-499e-bd12-5c415a58311f"
      },
      "source": [
        "The next thing to do is define what variables we want to plot.\n",
        "\n",
        "First, let's modify a few lines in *diagnostics/evaluation.yaml*.\n",
        "- Under **callbacks**, assure that every instance of **parameters** (should be three instances in total) calls back to the user-specified variables in **diagnostics.plot.parameters** (see cell below). This will make sure that plots include every variable that you would like to monitor.\n",
        "- You can leave the instance of **parameters** near the top of the file unchanged as we will be overriding it in *config.yaml*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f432e44-07ff-40b2-9ce3-8c1488e812be",
      "metadata": {
        "id": "3f432e44-07ff-40b2-9ce3-8c1488e812be"
      },
      "outputs": [],
      "source": [
        "parameters: ${diagnostics.plot.parameters}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44dc78fb-ee49-4040-8589-e2eb7368a350",
      "metadata": {
        "id": "44dc78fb-ee49-4040-8589-e2eb7368a350"
      },
      "source": [
        "Now that the plotting file is configured, we can add define the variables we want to plot in *config.yaml*.\n",
        "* Note that precipitation and related moisture variables need to be defined in **diagnostics.plot.precip_and_related_fields** as well as **diagnostics.plot.parameters**.\n",
        "\n",
        "Adding our desired variables for plotting to **diagnostics.plot** in *config.yaml*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45764717-ad87-4b42-a3fa-264034c368c1",
      "metadata": {
        "id": "45764717-ad87-4b42-a3fa-264034c368c1"
      },
      "outputs": [],
      "source": [
        "diagnostics:\n",
        "  log:\n",
        "    wandb:\n",
        "      entity: null\n",
        "    mlflow:\n",
        "      tracking_uri: null\n",
        "  plot:\n",
        "    frequency:\n",
        "      epoch: 1\n",
        "      batch: 5\n",
        "    parameters:\n",
        "      - tmp_825  # 825 hPa temperature\n",
        "      - tmp2m  # 2-meter temperature\n",
        "    precip_and_related_fields: []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20167b36-f068-43ec-a1ae-4d76e44ddf43",
      "metadata": {
        "id": "20167b36-f068-43ec-a1ae-4d76e44ddf43"
      },
      "source": [
        "### 3.5.3) Model Settings\n",
        "\n",
        "Several model configuration settings can be changed in *config.yaml*. By default, the *config.yaml* file will use the 'gnn' model. This is the Graph Neural Network architecture (https://arxiv.org/abs/1812.08434). These models are designed for learning relationships between nodes and edges. The two other model configurations available by default are the transformer (https://arxiv.org/abs/1706.03762) and graph transformer (https://arxiv.org/abs/2407.09777). Transformers excel at learning relationships between sequential data, such as sequential forecast timesteps in atmospheric data. The graph transformer combines the ideas of the GNN and transformer to handle sequential data connected through a graph.\n",
        "\n",
        "The *model* files generated by Anemoi all have ReLU (rectified linear unit) boundings applied to the variable 'tp', or total precipitation. The output of the ReLU function $y$ will be zero for a given input $x$ when $x\\leq0$, otherwise $y=x$. This means that the output of ReLU will never be negative, which makes since for precipitation.\n",
        "\n",
        "If you do not have precipitation in your dataset, you need can disable all boundings in *config.yaml* by passing an empty list to the *model.bounding* parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a9e2e0-c904-4667-86c2-7b9584d7b01c",
      "metadata": {
        "id": "56a9e2e0-c904-4667-86c2-7b9584d7b01c",
        "outputId": "d95bfec3-9bc8-4bbc-b3e4-fba09c04bd99"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2674895688.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel:\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "model:\n",
        "  bounding: []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbfba27c-e930-440f-9423-f99f4aa18eee",
      "metadata": {
        "id": "cbfba27c-e930-440f-9423-f99f4aa18eee"
      },
      "source": [
        "There are other model settings that can be configured in *config.yaml*.\n",
        "\n",
        "The model's graph can also be changed with the **graph** parameter under **defaults** the top of *config.yaml*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6ad9da-5bd8-42d2-a931-9dce5ffd6f8c",
      "metadata": {
        "id": "3f6ad9da-5bd8-42d2-a931-9dce5ffd6f8c"
      },
      "source": [
        "# 4) Set Environment Variables\n",
        "\n",
        "Anemoi requires a \"base seed\" and a SLURM job ID.\n",
        "- The base seed is used to initialize model weights. Changing the seed will result in different initial model parameters.\n",
        "- The SLURM job ID is required, even if you are not on SLURM (just leave it as \"0\").\n",
        "\n",
        "*Hydra* can be configured to output more complete tracebacks for debugging purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead33613-a578-4c21-8e4e-67881aeb2eda",
      "metadata": {
        "id": "ead33613-a578-4c21-8e4e-67881aeb2eda",
        "outputId": "d9b14930-04a2-412d-c278-df7e53c67363"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2674895688.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel:\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "model:\n",
        "  bounding: []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce40c91-442d-4533-8199-8465cdf61b41",
      "metadata": {
        "id": "7ce40c91-442d-4533-8199-8465cdf61b41"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "### Required ###\n",
        "os.environ[\"ANEMOI_BASE_SEED\"] = \"42\"\n",
        "os.environ[\"SLURM_JOB_ID\"] = \"0\"\n",
        "\n",
        "### Optional ###\n",
        "os.environ['HYDRA_FULL_ERROR'] = \"1\"  # for debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "279cc428-3369-42e4-9fd6-8abc9b8116a3",
      "metadata": {
        "id": "279cc428-3369-42e4-9fd6-8abc9b8116a3"
      },
      "source": [
        "## 5) Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7463104c-5f43-4b05-848d-5bcfa232d789",
      "metadata": {
        "id": "7463104c-5f43-4b05-848d-5bcfa232d789"
      },
      "outputs": [],
      "source": [
        "!anemoi-training train --config-name=config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17722f48-70fa-4c94-8bcd-88aa6847a41a",
      "metadata": {
        "id": "17722f48-70fa-4c94-8bcd-88aa6847a41a"
      },
      "source": [
        "## 6) Model Inference\n",
        "\n",
        "Model inference with Anemoi is performed with the *anemoi-inference* module: https://anemoi.readthedocs.io/projects/inference/en/latest/index.html#index-page"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bc7ed4-63df-448c-996a-a6401024ce52",
      "metadata": {
        "id": "c6bc7ed4-63df-448c-996a-a6401024ce52"
      },
      "source": [
        "### 6.1) Retrieve Model Runs and Load Checkpoint\n",
        "Each model run is saved in a folder with a random hash identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1406d5a0-9f10-4a02-bbf1-d907ea2b0a29",
      "metadata": {
        "id": "1406d5a0-9f10-4a02-bbf1-d907ea2b0a29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "model_runs = os.listdir('p1/training-output/checkpoint')\n",
        "print('Available model runs:')\n",
        "for run in model_runs:\n",
        "    print(run + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26dc6472-f2fe-4f08-a94c-715809cf674f",
      "metadata": {
        "id": "26dc6472-f2fe-4f08-a94c-715809cf674f"
      },
      "source": [
        "Select a model run from the list above and load the checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd3728f-99ca-42fb-a121-570ca90e220b",
      "metadata": {
        "id": "7fd3728f-99ca-42fb-a121-570ca90e220b"
      },
      "outputs": [],
      "source": [
        "model_run = 'd46e7b66-9ba1-474f-9142-5dd28be63f50'  # model run hash identifier\n",
        "\n",
        "## Do not change this ##\n",
        "checkpoint = f'p1/training-output/checkpoint/{model_run}/inference-last.ckpt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58da79c3-7478-4b8e-9e54-da2e50896c7f",
      "metadata": {
        "id": "58da79c3-7478-4b8e-9e54-da2e50896c7f"
      },
      "source": [
        "### 6.2) Configure and Run Model Inference\n",
        "Select a target forecast time (valid time) from the testing dataset and set a forecast lead time.\n",
        "\n",
        "You can also create and call a config YAML file that contains the inference settings, however all settings can be easily passed through the command line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b11141c-affd-4258-a42f-e9c07498ac3c",
      "metadata": {
        "scrolled": true,
        "id": "2b11141c-affd-4258-a42f-e9c07498ac3c"
      },
      "outputs": [],
      "source": [
        "forecast_time = '1994-03-31T21'  # valid time [YYYY]-[MM]-[DD]T[HH]\n",
        "lead_time = 12  # hours\n",
        "\n",
        "## Do not change these ##\n",
        "inference_dataset = 'p1/dataset/testing.zarr'\n",
        "output_file = 'forecast.nc'  # output file containing the model forecast\n",
        "\n",
        "!anemoi-inference run checkpoint={checkpoint} date={forecast_time} lead_time={lead_time} input.dataset={inference_dataset} output.netcdf={output_file}"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}