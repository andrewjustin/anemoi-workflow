{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f2d5fa-e962-4bce-8ff3-c03ec072addc",
   "metadata": {},
   "source": [
    "# 1) Generate Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df1fda-715f-4e38-850e-4e54ed19dedc",
   "metadata": {},
   "source": [
    "## 1.1) Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90c1b9d-b2c7-4d96-b903-1e5eb6727532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco training.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1e4c3-ccd0-4c00-83c1-12b1d2661ba2",
   "metadata": {},
   "source": [
    "## 1.2) Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f194c6a-d0d5-46b0-a977-38a046c9f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco validation.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1c92a-8762-4dd4-a8a4-95d0e1733fb1",
   "metadata": {},
   "source": [
    "## 1.3) Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715dd231-03cd-481d-950e-9a0ae224b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/ufs2arco/sources/cloud_zarr.py:36: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  xds = xr.open_zarr(\n"
     ]
    }
   ],
   "source": [
    "!ufs2arco testing.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f4a5f-bfe5-444c-8192-24dff163d48d",
   "metadata": {},
   "source": [
    "# 2) Generate and Modify Config Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69f2e1-ae5b-43ec-aac8-52bf948b8c91",
   "metadata": {},
   "source": [
    "## 2.1) Generate Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01ad47-a98e-4428-b12f-d5b3a84f9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-02 17:52:09 INFO Generating configs, please wait.\n"
     ]
    }
   ],
   "source": [
    "!anemoi-training config generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80579896-e0ae-4f19-bc57-60f8982ad949",
   "metadata": {},
   "source": [
    "The config files generated have many settings that need to be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6455de1-b5e3-420d-aa3e-58eaa497776a",
   "metadata": {},
   "source": [
    "## 2.2) Define batch sizes and configure datasets\n",
    "\n",
    "Batch sizes must be defined for each dataset. The default *dataloader* file *dataloader/native_grid.yaml* has pre-defined batch sizes, however these can be overriden in *config.yaml*.\n",
    "- **dataloader.batch_size.training**: training dataset batch size\n",
    "- **dataloader.batch_size.validation**: validation dataset batch size\n",
    "- **dataloader.batch_size.test**: testing dataset batch size\n",
    "\n",
    "For each dataset, the dataset path and start and end dates need to be specified.\n",
    "- **dataloader.training.dataset**: full path to the training dataset\n",
    "- **dataloader.training.start**: start date for training dataset (YYYY-MM-DD)\n",
    "- **dataloader.training.end**: end date for training dataset (YYYY-MM-DD)\n",
    "- **dataloader.validation.dataset**: full path to the validation dataset\n",
    "- **dataloader.validation.start**: start date for validation dataset (YYYY-MM-DD)\n",
    "- **dataloader.validation.end**: end date for validation dataset (YYYY-MM-DD)\n",
    "- **dataloader.test.dataset**: full path to the test dataset\n",
    "- **dataloader.test.start**: start date for test dataset (YYYY-MM-DD)\n",
    "- **dataloader.test.end**: end date for test dataset (YYYY-MM-DD)\n",
    "\n",
    "Example implementation in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1d45ee-0e0f-401a-8ecc-5e91cdb662e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (4061005375.py, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstart: 1994-01-01T00\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "dataloader:\n",
    "  batch_size:\n",
    "    training: 2\n",
    "    validation: 2\n",
    "    test: 2\n",
    "  training:\n",
    "    dataset: ${hardware.paths.data}/training.zarr\n",
    "    start: 1994-01-01\n",
    "    end: 1994-01-31\n",
    "  validation:\n",
    "    dataset: ${hardware.paths.data}/validation.zarr\n",
    "    start: 1994-02-01\n",
    "    end: 1994-02-28\n",
    "  test:\n",
    "    dataset: ${hardware.paths.data}/testing.zarr\n",
    "    start: 1994-03-01\n",
    "    end: 1994-03-31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a49d4d-20c0-4380-bccf-d22263497f56",
   "metadata": {},
   "source": [
    "## 2.3) Configure GPUs and Paths\n",
    "\n",
    "One of the most important steps for running the Anemoi framework is configuring paths. At the top of *config.yaml*, the 'hardware' parameter should be set to 'example'. This calls the default settings in *hardware/example.yaml*, however the **data** path is not specified in the *example* yaml. In addition, you may want to specify different directories for storing outputs and model graphs.\n",
    "\n",
    "- **hardware.paths.output**: directory for the outputs (checkpoints, plots, etc.). Directory structure will be created if it does not already exist.\n",
    "- **hardware.paths.data**: directory for the datasets generated with ufs2arco.\n",
    "- **hardware.paths.graph**: directory for the model graph.\n",
    "\n",
    "The name of the zarr file containing the training dataset must also be specified.\n",
    "- **hardware.files.dataset**: name of the training dataset zarr file (do not include absolute path with directory structure)\n",
    "\n",
    "You can also specify the number of GPUs to use for each model with the **hardware.num_gpus_per_model** parameter.\n",
    "\n",
    "An example implementation in *config.yaml* is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e2885-3cb3-4f68-bf83-4bd7ff5d65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardware:\n",
    "\n",
    "  num_gpus_per_model: 1\n",
    "\n",
    "  paths:\n",
    "    output: p1/training-output/\n",
    "    data: p1/dataset\n",
    "    graph: p1/graph\n",
    "\n",
    "  files:\n",
    "    dataset: training.zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ed49c-d159-4b4b-8751-19d78432b833",
   "metadata": {},
   "source": [
    "## 2.4) Configure Model Training\n",
    "\n",
    "There are a few parameters that should be specified in the main *config.yaml* file so model training configurations can be easily modified.\n",
    "\n",
    "At the top of *config.yaml*, you will probably see a 'training' parameter that is set to 'default'. This calls training configuration settings in the *training/default.yaml* file. All of these settings can be overriden in *config.yaml*.\n",
    "\n",
    "Here are some useful training parameters to include in *config.yaml*:\n",
    "- **training.max_epochs**: specifies the maximum number of epochs for model training. Training will stop if this limit is reached.\n",
    "- **training.max_steps**: specifies the maximum number of total steps for model training (*not steps per epoch*). Training will stop if this limit is reached.\n",
    "- **training.lr.rate**: starting learning rate\n",
    "- **training.lr.min**: minimum learning rate\n",
    "\n",
    "An example implementation in *config.yaml* with the aforementioned parameters is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf1895f-b515-4751-820e-8700917cd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "training:\n",
    "  max_epochs: 500\n",
    "  max_steps: 10000\n",
    "  lr:\n",
    "    rate: 1e-4\n",
    "    min: 3e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8c525-c0f6-481c-b7cc-978cd37b2ace",
   "metadata": {},
   "source": [
    "## 2.5) Configure Diagnostics\n",
    "\n",
    "During training, it is useful to plot sample model predictions and log other information pertaining to the model output/performance in order to get a good idea if your model is 'working' as intended.\n",
    "\n",
    "In the *config.yaml* file, the default file for diagnostics is *diagnostics/evaluation.yaml*. There are a couple empty fields that we will need to define in the following steps.\n",
    "\n",
    "### 2.5.1) Performance Logging\n",
    "\n",
    "For now, we will disable Weights and Biases for performance logging (though you may want to configure a WandB workflow in the future). This can be done by setting the **diagnostics.log.wandb.entity** parameter to 'null'.\n",
    "\n",
    "We will also disable the MLflow tracking server by setting **diagnostics.log.mlflow.tracking_uri** to 'null'.\n",
    "\n",
    "An example implementation in *config.yaml* is shown below. Note that we will continue to modify **diagnostics** in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee8437-e6a7-43c7-bd06-98aaccd88d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6c6d9-5db9-4d0a-b35f-52e13402f25c",
   "metadata": {},
   "source": [
    "### 2.5.2) Plotting\n",
    "\n",
    "With the default settings in *diagnostics/evaluation.yaml*, the following plots will be produced at user-defined frequencies for specified variables:\n",
    "* Spatial plots of model predictions and errors\n",
    "* Histograms showing binned model predictions and errors for **every** variable in a single plot\n",
    "\n",
    "The frequency of plotting can be modified directly in *config.yaml* with the following parameters:\n",
    "* **diagnostics.plot.frequency.epoch**: plot frequency in epochs\n",
    "* **diagnostics.plot.frequency.batch**: plot frequency in batches\n",
    "\n",
    "Adding these to **diagnostics** in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14c0af-a659-4e3c-8470-496084e99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null\n",
    "  plot:\n",
    "    frequency:\n",
    "      epoch: 5\n",
    "      batch: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01aa95-30a3-499e-bd12-5c415a58311f",
   "metadata": {},
   "source": [
    "The next thing to do is define what variables we want to plot. \n",
    "\n",
    "First, let's modify a few lines in *diagnostics/evaluation.yaml*.\n",
    "- Under **callbacks**, assure that every instance of **parameters** (should be three instances in total) calls back to the user-specified variables in **diagnostics.plot.parameters** (see cell below). This will make sure that plots include every variable that you would like to monitor.\n",
    "- You can leave the instance of **parameters** near the top of the file unchanged as we will be overriding it in *config.yaml*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f432e44-07ff-40b2-9ce3-8c1488e812be",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters: ${diagnostics.plot.parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc78fb-ee49-4040-8589-e2eb7368a350",
   "metadata": {},
   "source": [
    "Now that the plotting file is configured, we can add define the variables we want to plot in *config.yaml*.\n",
    "* Note that precipitation and related moisture variables need to be defined in **diagnostics.plot.precip_and_related_fields** as well as **diagnostics.plot.parameters**.\n",
    "\n",
    "Adding our desired variables for plotting to **diagnostics.plot** in *config.yaml*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45764717-ad87-4b42-a3fa-264034c368c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics:\n",
    "  log:\n",
    "    wandb:\n",
    "      entity: null\n",
    "    mlflow:\n",
    "      tracking_uri: null\n",
    "  plot:\n",
    "    frequency:\n",
    "      epoch: 1\n",
    "      batch: 5\n",
    "    parameters:\n",
    "      - tmp_825  # 825 hPa temperature\n",
    "      - tmp2m  # 2-meter temperature\n",
    "    precip_and_related_fields: []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20167b36-f068-43ec-a1ae-4d76e44ddf43",
   "metadata": {},
   "source": [
    "After configuring the diagnostics, the *config.yaml* file can be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ad9da-5bd8-42d2-a931-9dce5ffd6f8c",
   "metadata": {},
   "source": [
    "# 3) Set Environment Variables\n",
    "\n",
    "Anemoi requires a \"base seed\" and a SLURM job ID.\n",
    "- The base seed is used to initialize model weights. Changing the seed will result in different initial model parameters.\n",
    "- The SLURM job ID is required, even if you are not on SLURM (just leave it as \"0\").\n",
    "\n",
    "*Hydra* can be configured to output more complete tracebacks for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce40c91-442d-4533-8199-8465cdf61b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### Required ###\n",
    "os.environ[\"ANEMOI_BASE_SEED\"] = \"42\"\n",
    "os.environ[\"SLURM_JOB_ID\"] = \"0\"\n",
    "\n",
    "### Optional ###\n",
    "os.environ['HYDRA_FULL_ERROR'] = \"1\"  # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cc428-3369-42e4-9fd6-8abc9b8116a3",
   "metadata": {},
   "source": [
    "## 4) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463104c-5f43-4b05-848d-5bcfa232d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "!anemoi-training train --config-name=config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17722f48-70fa-4c94-8bcd-88aa6847a41a",
   "metadata": {},
   "source": [
    "## 5) Model Inference\n",
    "\n",
    "Model inference with Anemoi is performed with the *anemoi-inference* module: https://anemoi.readthedocs.io/projects/inference/en/latest/index.html#index-page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc7ed4-63df-448c-996a-a6401024ce52",
   "metadata": {},
   "source": [
    "### 5.1) Retrieve Model Runs and Load Checkpoint\n",
    "Each model run is saved in a folder with a random hash identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1406d5a0-9f10-4a02-bbf1-d907ea2b0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model runs:\n",
      "d46e7b66-9ba1-474f-9142-5dd28be63f50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_runs = os.listdir('p1/training-output/checkpoint')\n",
    "print('Available model runs:')\n",
    "for run in model_runs:\n",
    "    print(run + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc6472-f2fe-4f08-a94c-715809cf674f",
   "metadata": {},
   "source": [
    "Select a model run from the list above and load the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd3728f-99ca-42fb-a121-570ca90e220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = 'd46e7b66-9ba1-474f-9142-5dd28be63f50'  # model run hash identifier\n",
    "\n",
    "## Do not change this ##\n",
    "checkpoint = f'p1/training-output/checkpoint/{model_run}/inference-last.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da79c3-7478-4b8e-9e54-da2e50896c7f",
   "metadata": {},
   "source": [
    "### 5.2) Configure and Run Model Inference\n",
    "Select a target forecast time (valid time) from the testing dataset and set a forecast lead time.\n",
    "\n",
    "You can also create and call a config YAML file that contains the inference settings, however all settings can be easily passed through the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b11141c-affd-4258-a42f-e9c07498ac3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrewjustin/miniconda3/envs/anemoi-ufs2arco/lib/python3.11/site-packages/anemoi/inference/runners/default.py:283: UserWarning: \n",
      "                No post_processors defined. Accumulations will be accumulated from the beginning of the forecast.\n",
      "\n",
      "                ğŸš§ğŸš§ğŸš§ In a future release, the default will be to NOT accumulate from the beginning of the forecast. ğŸš§ğŸš§ğŸš§\n",
      "                Update your config if you wish to keep accumulating from the beginning.\n",
      "                https://github.com/ecmwf/anemoi-inference/issues/131\n",
      "                \n",
      "  warnings.warn(\n",
      "2025-07-08 17:08:42 INFO Pre processors: []\n",
      "2025-07-08 17:08:42 INFO Accumulating fields []\n",
      "2025-07-08 17:08:42 INFO Post processors: [Accumulate([])]\n",
      "2025-07-08 17:08:42 INFO Using DefaultRunner runner, device=cuda\n",
      "2025-07-08 17:08:42 INFO Input: DatasetInput(('p1/dataset/testing.zarr',), {})\n",
      "2025-07-08 17:08:42 INFO Output: NetCDFOutput(forecast.nc)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX cos_julian_day, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX cos_local_time, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX cos_longitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX hgtsfc_static, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX insolation, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX land_static, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh2m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX pressfc, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX sin_julian_day, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX sin_latitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX sin_local_time, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX sin_longitude, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp2m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd10m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_225, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_275, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_325, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_375, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_425, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_475, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_525, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_575, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_625, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_675, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_725, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_775, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_825, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_875, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_925, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_975, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd10m, 0, (73728,)\n",
      "2025-07-08 17:08:42 INFO Computed constant forcings: before ['cos_longitude', 'sin_latitude', 'sin_longitude'], after []\n",
      "2025-07-08 17:08:42 INFO Dynamic computed forcing: ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Input state:\n",
      "2025-07-08 17:08:42 INFO   ['cos_julian_day', 'cos_local_time', 'cos_longitude', 'dzdt_225', 'dzdt_275', 'dzdt_325', 'dzdt_375', 'dzdt_425', 'dzdt_475', 'dzdt_525', 'dzdt_575', 'dzdt_625', 'dzdt_675', 'dzdt_725', 'dzdt_775', 'dzdt_825', 'dzdt_875', 'dzdt_925', 'dzdt_975', 'hgtsfc_static', 'insolation', 'land_static', 'log_spfh_225', 'log_spfh_275', 'log_spfh_325', 'log_spfh_375', 'log_spfh_425', 'log_spfh_475', 'log_spfh_525', 'log_spfh_575', 'log_spfh_625', 'log_spfh_675', 'log_spfh_725', 'log_spfh_775', 'log_spfh_825', 'log_spfh_875', 'log_spfh_925', 'log_spfh_975', 'log_spfh2m', 'pressfc', 'sin_julian_day', 'sin_latitude', 'sin_local_time', 'sin_longitude', 'tmp_225', 'tmp_275', 'tmp_325', 'tmp_375', 'tmp_425', 'tmp_475', 'tmp_525', 'tmp_575', 'tmp_625', 'tmp_675', 'tmp_725', 'tmp_775', 'tmp_825', 'tmp_875', 'tmp_925', 'tmp_975', 'tmp2m', 'ugrd_225', 'ugrd_275', 'ugrd_325', 'ugrd_375', 'ugrd_425', 'ugrd_475', 'ugrd_525', 'ugrd_575', 'ugrd_625', 'ugrd_675', 'ugrd_725', 'ugrd_775', 'ugrd_825', 'ugrd_875', 'ugrd_925', 'ugrd_975', 'ugrd10m', 'vgrd_225', 'vgrd_275', 'vgrd_325', 'vgrd_375', 'vgrd_425', 'vgrd_475', 'vgrd_525', 'vgrd_575', 'vgrd_625', 'vgrd_675', 'vgrd_725', 'vgrd_775', 'vgrd_825', 'vgrd_875', 'vgrd_925', 'vgrd_975', 'vgrd10m']\n",
      "2025-07-08 17:08:42 INFO Constant forcings inputs:\n",
      "2025-07-08 17:08:42 INFO Dynamic forcings inputs:\n",
      "2025-07-08 17:08:42 INFO   ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO Boundary forcings inputs:\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Initial forcings:\n",
      "2025-07-08 17:08:42 INFO   Constant forcings inputs:\n",
      "2025-07-08 17:08:42 INFO   Dynamic forcings inputs:\n",
      "2025-07-08 17:08:42 INFO     ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'])\n",
      "2025-07-08 17:08:42 INFO --------------------------------------------------------------------------------\n",
      "2025-07-08 17:08:42 INFO Dynamic forcings input: ComputedForcings(['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time']) ['cos_julian_day', 'cos_local_time', 'insolation', 'sin_julian_day', 'sin_local_time'] ([datetime.datetime(1994, 3, 31, 15, 0), datetime.datetime(1994, 3, 31, 21, 0)])\n",
      "2025-07-08 17:08:42 INFO Expected shape for each input fields: (2, 73728)\n",
      "2025-07-08 17:08:43 INFO Preparing input tensor with shape (2, 95, 73728)\n",
      "2025-07-08 17:08:46 INFO Loading Checkpoint(p1/training-output/checkpoint/d46e7b66-9ba1-474f-9142-5dd28be63f50/inference-last.ckpt): 3 seconds.\n",
      "2025-07-08 17:08:46 INFO Lead time: 12:00:00, time stepping: 6:00:00 Forecasting 2 steps\n",
      "2025-07-08 17:08:47 INFO Forecasting step 6:00:00 (1994-04-01 03:00:00): 0.7 seconds.\n",
      "2025-07-08 17:08:47 INFO Post processor: Accumulate([])\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX hgtsfc_static, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX land_static, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh2m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX pressfc, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp2m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd10m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_225, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_275, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_325, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_375, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_425, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_475, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_525, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_575, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_625, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_675, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_725, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_775, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_825, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_875, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_925, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_975, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd10m, 1, (73728,)\n",
      "2025-07-08 17:08:47 INFO Forecasting step 12:00:00 (1994-04-01 09:00:00): 21.8 milliseconds.\n",
      "2025-07-08 17:08:47 INFO Post processor: Accumulate([])\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX dzdt_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX hgtsfc_static, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX land_static, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX log_spfh2m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX pressfc, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX tmp2m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX ugrd10m, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_225, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_275, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_325, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_375, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_425, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_475, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_525, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_575, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_625, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_675, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_725, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_775, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_825, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_875, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_925, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd_975, 2, (73728,)\n",
      "2025-07-08 17:08:47 INFO ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ XXXXXX vgrd10m, 2, (73728,)\n"
     ]
    }
   ],
   "source": [
    "forecast_time = '1994-03-31T21'  # valid time [YYYY]-[MM]-[DD]T[HH]\n",
    "lead_time = 12  # hours\n",
    "\n",
    "## Do not change these ##\n",
    "inference_dataset = 'p1/dataset/testing.zarr'\n",
    "output_file = 'forecast.nc'  # output file containing the model forecast\n",
    "\n",
    "!anemoi-inference run checkpoint={checkpoint} date={forecast_time} lead_time={lead_time} input.dataset={inference_dataset} output.netcdf={output_file}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
